#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –∫–Ω–∏–≥ –∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –æ–ø–∏—Å–∞–Ω–∏–π.
"""

import sys
import os
import asyncio
from uuid import UUID
from typing import List

sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from app.core.database import AsyncSessionLocal
from app.models.book import Book
from app.models.chapter import Chapter
from app.models.description import Description
from app.services.nlp_processor import nlp_processor
from sqlalchemy import select
from sqlalchemy.orm import selectinload

async def process_book_descriptions(book_id: UUID) -> int:
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ–ø–∏—Å–∞–Ω–∏—è –¥–ª—è –æ–¥–Ω–æ–π –∫–Ω–∏–≥–∏."""
    descriptions_count = 0
    
    async with AsyncSessionLocal() as db:
        # –ü–æ–ª—É—á–∞–µ–º –∫–Ω–∏–≥—É —Å –≥–ª–∞–≤–∞–º–∏
        result = await db.execute(
            select(Book)
            .options(selectinload(Book.chapters))
            .where(Book.id == book_id)
        )
        book = result.scalar_one_or_none()
        
        if not book:
            print(f"‚ùå –ö–Ω–∏–≥–∞ {book_id} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
            return 0
            
        print(f"üìñ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º: {book.title}")
        print(f"   –ì–ª–∞–≤: {len(book.chapters)}")
        
        for chapter in book.chapters:
            if chapter.is_description_parsed:
                print(f"   ‚è≠Ô∏è  –ì–ª–∞–≤–∞ {chapter.chapter_number} —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞")
                continue
                
            print(f"   üîÑ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≥–ª–∞–≤—É {chapter.chapter_number}: {chapter.title}")
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ–ø–∏—Å–∞–Ω–∏—è —Å –ø–æ–º–æ—â—å—é NLP
            try:
                descriptions_data = nlp_processor.extract_descriptions_from_text(
                    text=chapter.content,
                    chapter_id=str(chapter.id)
                )
                
                print(f"      –ù–∞–π–¥–µ–Ω–æ –æ–ø–∏—Å–∞–Ω–∏–π: {len(descriptions_data)}")
                
                # –°–æ–∑–¥–∞—ë–º –æ–±—ä–µ–∫—Ç—ã –æ–ø–∏—Å–∞–Ω–∏–π
                for desc_data in descriptions_data:
                    description = Description(
                        chapter_id=chapter.id,
                        type=desc_data["type"],
                        content=desc_data["content"],
                        context=desc_data.get("context", ""),
                        confidence_score=desc_data["confidence_score"],
                        priority_score=desc_data["priority_score"],
                        position_in_chapter=desc_data.get("position_in_chapter", 0),
                        word_count=len(desc_data["content"].split()),
                        entities_mentioned=desc_data.get("entities_mentioned", []),
                        emotional_tone=desc_data.get("emotional_tone", "neutral"),
                        complexity_level=desc_data.get("complexity_level", "medium"),
                        is_suitable_for_generation=desc_data.get("confidence_score", 0) >= 0.3
                    )
                    db.add(description)
                    descriptions_count += 1
                
                # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –≥–ª–∞–≤—ã
                chapter.is_description_parsed = True
                chapter.descriptions_found = len(descriptions_data)
                chapter.parsing_progress = 100.0
                
                print(f"      ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(descriptions_data)} –æ–ø–∏—Å–∞–Ω–∏–π")
                
            except Exception as e:
                print(f"      ‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {str(e)}")
                continue
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏—è
        await db.commit()
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –∫–Ω–∏–≥–∏
        book.is_parsed = True
        await db.commit()
        
    return descriptions_count

async def main():
    print("=" * 60)
    print("–û–ë–†–ê–ë–û–¢–ö–ê –°–£–©–ï–°–¢–í–£–Æ–©–ò–• –ö–ù–ò–ì")
    print("=" * 60)
    
    if not nlp_processor.is_available():
        print("‚ùå NLP –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω!")
        print("–ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª–∏...")
        nlp_processor.load_models()
    
    print("‚úÖ NLP –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –≥–æ—Ç–æ–≤")
    
    async with AsyncSessionLocal() as db:
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –∫–Ω–∏–≥–∏
        result = await db.execute(select(Book))
        books = result.scalars().all()
        
        if not books:
            print("‚ùå –ö–Ω–∏–≥–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö")
            return
        
        print(f"\n‚úÖ –ù–∞–π–¥–µ–Ω–æ –∫–Ω–∏–≥: {len(books)}")
        print("-" * 60)
        
        total_descriptions = 0
        processed_books = 0
        
        for book in books:
            try:
                descriptions_count = await process_book_descriptions(book.id)
                total_descriptions += descriptions_count
                processed_books += 1
                print(f"‚úÖ –ö–Ω–∏–≥–∞ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞: {descriptions_count} –æ–ø–∏—Å–∞–Ω–∏–π")
                
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–Ω–∏–≥–∏ {book.title}: {str(e)}")
                continue
    
    print("\n" + "=" * 60)
    print("–û–ë–†–ê–ë–û–¢–ö–ê –ó–ê–í–ï–†–®–ï–ù–ê")
    print(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∫–Ω–∏–≥: {processed_books}")
    print(f"–í—Å–µ–≥–æ –æ–ø–∏—Å–∞–Ω–∏–π: {total_descriptions}")
    print("=" * 60)

if __name__ == "__main__":
    asyncio.run(main())