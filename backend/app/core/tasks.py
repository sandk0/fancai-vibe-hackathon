"""
Background tasks for BookReader AI.
–§–æ–Ω–æ–≤—ã–µ –∑–∞–¥–∞—á–∏ –¥–ª—è BookReader AI.

NLP REMOVAL (December 2025):
- –£–¥–∞–ª–µ–Ω multi_nlp_manager (—Ç—Ä–µ–±–æ–≤–∞–ª 10-12 –ì–ë RAM)
- –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è langextract_processor (LLM-based, ~500 –ú–ë)
- –û–ø–∏—Å–∞–Ω–∏—è –∏–∑–≤–ª–µ–∫–∞—é—Ç—Å—è on-demand, –Ω–µ —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –≤ –ë–î
- –ó–∞–¥–∞—á–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–Ω–∏–≥ —É–ø—Ä–æ—â–µ–Ω—ã
"""

from app.core.celery_app import celery_app
import asyncio
import os
from typing import Dict, Any, List
import logging
from datetime import datetime, timezone
from uuid import UUID
from sqlalchemy import select

from app.core.database import AsyncSessionLocal
from app.models.book import Book
from app.models.chapter import Chapter
from app.services.image_generator import image_generator_service

logger = logging.getLogger(__name__)


def _run_async_task(coro):
    """
    Helper function to run async functions in Celery tasks.

    –í–ê–ñ–ù–û: –ù–ï –∑–∞–∫—Ä—ã–≤–∞–µ–º event loop –ø–æ—Å–ª–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è, —Ç–∞–∫ –∫–∞–∫:
    1. –ü–æ—Å–ª–µ run_until_complete() loop —É–∂–µ –Ω–µ running
    2. –ó–∞–∫—Ä—ã—Ç–∏–µ loop –º–æ–∂–µ—Ç —Å–ª–æ–º–∞—Ç—å –ø–æ—Å–ª–µ–¥—É—é—â–∏–µ async –æ–ø–µ—Ä–∞—Ü–∏–∏
    3. –ü–æ–∑–≤–æ–ª—è–µ–º asyncio —É–ø—Ä–∞–≤–ª—è—Ç—å –∂–∏–∑–Ω–µ–Ω–Ω—ã–º —Ü–∏–∫–ª–æ–º loop
    """
    try:
        loop = asyncio.get_event_loop()
    except RuntimeError:
        # Worker thread –Ω–µ –∏–º–µ–µ—Ç event loop - —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)

    try:
        return loop.run_until_complete(coro)
    finally:
        # –ù–ï –∑–∞–∫—Ä—ã–≤–∞–µ–º loop - –ø–æ–∑–≤–æ–ª—è–µ–º asyncio —É–ø—Ä–∞–≤–ª—è—Ç—å –∏–º
        pass


@celery_app.task(name="process_book", bind=True, max_retries=3, default_retry_delay=60)
def process_book_task(self, book_id_str: str) -> Dict[str, Any]:
    """
    –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∫–Ω–∏–≥–∏: –≤–∞–ª–∏–¥–∞—Ü–∏—è –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫ on-demand –∏–∑–≤–ª–µ—á–µ–Ω–∏—é.

    –ü–æ—Å–ª–µ —É–¥–∞–ª–µ–Ω–∏—è NLP —Å–∏—Å—Ç–µ–º—ã —ç—Ç–∞ –∑–∞–¥–∞—á–∞ —Ç–æ–ª—å–∫–æ:
    - –í–∞–ª–∏–¥–∏—Ä—É–µ—Ç –∫–Ω–∏–≥—É –∏ –≥–ª–∞–≤—ã
    - –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å LLM
    - –ü–æ–º–µ—á–∞–µ—Ç –∫–Ω–∏–≥—É –∫–∞–∫ –≥–æ—Ç–æ–≤—É—é –∫ –æ–±—Ä–∞–±–æ—Ç–∫–µ

    Args:
        book_id_str: String ID –∫–Ω–∏–≥–∏ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ (UUID)

    Returns:
        –†–µ–∑—É–ª—å—Ç–∞—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏
    """
    try:
        print(f"üöÄ [CELERY TASK] Starting book processing for book_id={book_id_str}")
        book_id = UUID(book_id_str)
        logger.info(f"Starting book processing for book_id={book_id}")

        result = _run_async_task(_process_book_async(book_id))

        print(
            f"‚úÖ [CELERY TASK] Book processing completed for book_id={book_id}, result: {result}"
        )
        logger.info(f"Book processing completed for book_id={book_id}")
        return result

    except Exception as e:
        error_msg = f"Error processing book {book_id_str}: {str(e)}"
        print(f"‚ùå [CELERY TASK] {error_msg}")
        logger.error(error_msg)
        import traceback

        print(f"üîç [CELERY TASK] Full traceback: {traceback.format_exc()}")
        return {"book_id": book_id_str, "status": "failed", "error": str(e)}


async def _process_book_async(book_id: UUID) -> Dict[str, Any]:
    """
    –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–Ω–∏–≥–∏.

    –ü–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏:
    1. –í–∞–ª–∏–¥–∏—Ä—É–µ—Ç –∫–Ω–∏–≥—É –∏ –≥–ª–∞–≤—ã
    2. –ü–∞—Ä—Å–∏—Ç –ø–µ—Ä–≤—ã–µ 2 –≥–ª–∞–≤—ã —Å –ø–æ–º–æ—â—å—é LLM –¥–ª—è –ø—Ä–µ–¥–∑–∞–≥—Ä—É–∑–∫–∏
    3. –ü–æ–º–µ—á–∞–µ—Ç –∫–Ω–∏–≥—É –∫–∞–∫ –≥–æ—Ç–æ–≤—É—é
    """
    from app.services.langextract_processor import langextract_processor
    from app.models.description import Description, DescriptionType

    async with AsyncSessionLocal() as db:
        print(f"üîç [ASYNC TASK] Starting async processing for book {book_id}")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å LLM
        llm_available = langextract_processor.is_available()

        if not llm_available:
            print("‚ö†Ô∏è [ASYNC TASK] LangExtract not available - checking API key")
            logger.warning("LangExtract processor not available")

        # –ü–æ–ª—É—á–∞–µ–º –∫–Ω–∏–≥—É
        book_result = await db.execute(select(Book).where(Book.id == book_id))
        book = book_result.scalar_one_or_none()

        if not book:
            error_msg = f"Book with id {book_id} not found"
            print(f"‚ùå [ASYNC TASK] {error_msg}")
            raise ValueError(error_msg)

        print(f"üìö [ASYNC TASK] Found book: {book.title} by {book.author}")

        # –ü–æ–ª—É—á–∞–µ–º –≥–ª–∞–≤—ã
        chapters_result = await db.execute(
            select(Chapter)
            .where(Chapter.book_id == book_id)
            .order_by(Chapter.chapter_number)
        )
        chapters = chapters_result.scalars().all()

        print(f"üìñ [ASYNC TASK] Found {len(chapters)} chapters")

        # –ü–∞—Ä—Å–∏–º –ø–µ—Ä–≤—ã–µ 5 –≥–ª–∞–≤ —Å –ø–æ–º–æ—â—å—é LLM (increased from 2 for better UX)
        # UPDATED (2025-12-25): Expanded pre-parsing for faster initial experience
        chapters_parsed = 0
        total_descriptions = 0
        CHAPTERS_TO_PREPARSE = 5

        if llm_available and chapters:
            for chapter in chapters[:CHAPTERS_TO_PREPARSE]:
                try:
                    print(f"üîÑ [ASYNC TASK] Parsing chapter {chapter.chapter_number}: {chapter.title}")

                    # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–ª—É–∂–µ–±–Ω—ã–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
                    SERVICE_PAGE_KEYWORDS = [
                        "—Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ", "–æ–≥–ª–∞–≤–ª–µ–Ω–∏–µ", "table of contents", "contents",
                        "–æ—Ç –∞–≤—Ç–æ—Ä–∞", "—Å–ª–æ–≤–æ –∞–≤—Ç–æ—Ä–∞", "–ø—Ä–µ–¥–∏—Å–ª–æ–≤–∏–µ", "–ø–æ—Å–ª–µ—Å–ª–æ–≤–∏–µ",
                        "–∞–Ω–Ω–æ—Ç–∞—Ü–∏—è", "annotation", "synopsis",
                        "—ç–ø–∏–≥—Ä–∞—Ñ", "epigraph", "—Ü–∏—Ç–∞—Ç–∞",
                        "–ø–æ—Å–≤—è—â–µ–Ω–∏–µ", "dedication",
                        "–±–ª–∞–≥–æ–¥–∞—Ä–Ω–æ—Å—Ç–∏", "acknowledgments",
                        "–ø—Ä–∏–º–µ—á–∞–Ω–∏—è", "notes", "—Å–Ω–æ—Å–∫–∏",
                        "–±–∏–±–ª–∏–æ–≥—Ä–∞—Ñ–∏—è", "bibliography", "references",
                        "–æ–± –∞–≤—Ç–æ—Ä–µ", "about the author", "–±–∏–æ–≥—Ä–∞—Ñ–∏—è",
                        "copyright", "–∏–∑–¥–∞—Ç–µ–ª—å—Å—Ç–≤–æ", "publisher",
                        "isbn", "–≤—Å–µ –ø—Ä–∞–≤–∞ –∑–∞—â–∏—â–µ–Ω—ã", "all rights reserved",
                    ]

                    chapter_title_lower = (chapter.title or "").lower()
                    chapter_content_lower = (chapter.content or "")[:500].lower()

                    is_service_page = any(
                        keyword in chapter_title_lower or keyword in chapter_content_lower
                        for keyword in SERVICE_PAGE_KEYWORDS
                    )

                    if chapter.word_count and chapter.word_count < 100:
                        is_service_page = True

                    # P1.1: Use cached is_service_page method
                    if chapter.is_service_page is None:
                        chapter.is_service_page = is_service_page

                    if is_service_page:
                        print(f"‚è≠Ô∏è [ASYNC TASK] Skipping service page: {chapter.title}")
                        chapter.is_description_parsed = True
                        chapter.parsed_at = datetime.now(timezone.utc)
                        continue

                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ–ø–∏—Å–∞–Ω–∏—è —á–µ—Ä–µ–∑ LLM
                    result = await langextract_processor.extract_descriptions(chapter.content)
                    descriptions_data = result.descriptions if result.descriptions else []

                    print(f"‚úÖ [ASYNC TASK] Extracted {len(descriptions_data)} descriptions from chapter {chapter.chapter_number}")

                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–ø–∏—Å–∞–Ω–∏—è –≤ –±–∞–∑—É
                    position = 0
                    for desc_data in descriptions_data:
                        desc_dict = desc_data.to_dict() if hasattr(desc_data, 'to_dict') else desc_data

                        # Map string type to enum
                        type_str = desc_dict.get("type", "location")
                        try:
                            desc_type = DescriptionType(type_str)
                        except ValueError:
                            desc_type = DescriptionType.LOCATION

                        new_description = Description(
                            chapter_id=chapter.id,
                            type=desc_type,
                            content=desc_dict.get("content", ""),
                            confidence_score=desc_dict.get("confidence_score", 0.8),
                            priority_score=desc_dict.get("priority_score", 0.5),
                            entities_mentioned=",".join(desc_dict.get("entities_mentioned", [])),
                            position_in_chapter=position,
                            word_count=desc_dict.get("word_count", len(desc_dict.get("content", "").split())),
                        )
                        position += 1
                        db.add(new_description)
                        total_descriptions += 1

                    # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –≥–ª–∞–≤—ã
                    chapter.descriptions_found = len(descriptions_data)
                    chapter.is_description_parsed = True
                    chapter.parsed_at = datetime.now(timezone.utc)
                    chapters_parsed += 1

                    # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –∫–Ω–∏–≥–∏ (–Ω–æ –ù–ï –∫–æ–º–º–∏—Ç–∏–º –µ—â—ë)
                    book.parsing_progress = int((chapters_parsed / CHAPTERS_TO_PREPARSE) * 100)
                    # P2.2: Removed per-chapter commit, will batch commit below

                except Exception as e:
                    print(f"‚ùå [ASYNC TASK] Error parsing chapter {chapter.chapter_number}: {str(e)}")
                    import traceback
                    print(f"üîç [ASYNC TASK] Traceback: {traceback.format_exc()}")
                    # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Å —Å–ª–µ–¥—É—é—â–µ–π –≥–ª–∞–≤–æ–π
                    continue

            # P2.2: BATCH COMMIT after all chapters processed (was: commit per chapter)
            # Saves ~200ms (5 chapters * 40ms per commit)
            await db.commit()
            print(f"üíæ [ASYNC TASK] Batch committed {chapters_parsed} chapters")

        # –ü–æ–º–µ—á–∞–µ–º –∫–Ω–∏–≥—É –∫–∞–∫ –≥–æ—Ç–æ–≤—É—é
        book.is_processing = False
        book.is_parsed = True
        book.parsing_progress = 100
        await db.commit()

        # –ò–Ω–≤–∞–ª–∏–¥–∏—Ä—É–µ–º –∫—ç—à
        try:
            from app.core.cache import cache_manager
            print(f"[CACHE] Invalidating book list cache for user {book.user_id}")
            pattern = f"user:{book.user_id}:books:*"
            deleted_count = await cache_manager.delete_pattern(pattern)
            print(f"[CACHE] Cache invalidated ({deleted_count} keys deleted)")
        except Exception as e:
            print(f"[CACHE ERROR] Failed to invalidate cache: {str(e)}")

        result = {
            "book_id": str(book_id),
            "status": "completed",
            "chapters_count": len(chapters),
            "chapters_preparsed": chapters_parsed,
            "descriptions_extracted": total_descriptions,
            "llm_available": llm_available,
            "extraction_mode": "preparse_first_chapters",
            "message": f"Book ready. Pre-parsed {chapters_parsed} chapters with {total_descriptions} descriptions."
        }

        print(f"üéâ [ASYNC TASK] Final result: {result}")
        return result


@celery_app.task(name="generate_image_for_text")
def generate_image_for_text_task(
    text: str,
    chapter_id_str: str,
    user_id_str: str,
    description_type: str = "location"
) -> Dict[str, Any]:
    """
    –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –æ–ø–∏—Å–∞–Ω–∏—è.

    –ü–æ—Å–ª–µ —É–¥–∞–ª–µ–Ω–∏—è NLP: –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≥–µ–Ω–µ—Ä–∏—Ä—É—é—Ç—Å—è –Ω–∞–ø—Ä—è–º—É—é –∏–∑ —Ç–µ–∫—Å—Ç–∞,
    –±–µ–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ —Ç–∞–±–ª–∏—Ü—É descriptions.

    Args:
        text: –¢–µ–∫—Å—Ç –æ–ø–∏—Å–∞–Ω–∏—è –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
        chapter_id_str: String ID –≥–ª–∞–≤—ã
        user_id_str: String ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        description_type: –¢–∏–ø –æ–ø–∏—Å–∞–Ω–∏—è (location, character, atmosphere)

    Returns:
        –†–µ–∑—É–ª—å—Ç–∞—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
    """
    try:
        logger.info(f"Starting image generation for chapter {chapter_id_str}")

        result = _run_async_task(
            _generate_image_for_text_async(text, chapter_id_str, user_id_str, description_type)
        )

        logger.info(f"Image generation completed for chapter {chapter_id_str}")
        return result

    except Exception as e:
        logger.error(f"Error generating image: {str(e)}")
        return {"chapter_id": chapter_id_str, "status": "failed", "error": str(e)}


async def _generate_image_for_text_async(
    text: str,
    chapter_id_str: str,
    user_id_str: str,
    description_type: str
) -> Dict[str, Any]:
    """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑ —Ç–µ–∫—Å—Ç–∞."""
    async with AsyncSessionLocal() as db:
        user_id = UUID(user_id_str)
        chapter_id = UUID(chapter_id_str)

        try:
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–∞–ø—Ä—è–º—É—é
            generation_result = await image_generator_service.generate_image_from_text(
                text=text,
                description_type=description_type,
                user_id=str(user_id),
            )

            if generation_result.success:
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                from app.models.image import GeneratedImage

                generated_image = GeneratedImage(
                    chapter_id=chapter_id,
                    user_id=user_id,
                    image_url=generation_result.image_url,
                    local_path=generation_result.local_path,
                    generation_prompt=text[:500],  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–∞—á–∞–ª–æ —Ç–µ–∫—Å—Ç–∞
                    description_text=text,  # –î–µ–Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ –ø–æ–ª–µ
                    description_type=description_type,
                    generation_time_seconds=generation_result.generation_time_seconds,
                )

                db.add(generated_image)
                await db.commit()
                await db.refresh(generated_image)

                return {
                    "id": str(generated_image.id),
                    "chapter_id": chapter_id_str,
                    "image_url": generation_result.image_url,
                    "generation_time": generation_result.generation_time_seconds,
                    "status": "success"
                }
            else:
                return {
                    "chapter_id": chapter_id_str,
                    "status": "failed",
                    "error": generation_result.error_message
                }

        except Exception as e:
            logger.error(f"Error generating image for chapter {chapter_id_str}: {str(e)}")
            return {
                "chapter_id": chapter_id_str,
                "status": "failed",
                "error": str(e)
            }


@celery_app.task(name="cleanup_old_images")
def cleanup_old_images_task(days_old: int = 30) -> Dict[str, Any]:
    """
    –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π.

    Args:
        days_old: –£–¥–∞–ª–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å—Ç–∞—Ä—à–µ —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –¥–Ω–µ–π

    Returns:
        –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–¥–∞–ª–µ–Ω–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    """
    try:
        logger.info(f"Starting cleanup of images older than {days_old} days")

        result = _run_async_task(_cleanup_old_images_async(days_old))

        logger.info("Image cleanup completed")
        return result

    except Exception as e:
        logger.error(f"Error in image cleanup: {str(e)}")
        return {"status": "failed", "error": str(e)}


async def _cleanup_old_images_async(days_old: int) -> Dict[str, Any]:
    """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ—á–∏—Å—Ç–∫–∏ —Å—Ç–∞—Ä—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π."""
    from datetime import timedelta
    import os
    from app.models.image import GeneratedImage

    async with AsyncSessionLocal() as db:
        cutoff_date = datetime.now(timezone.utc) - timedelta(days=days_old)

        old_images_result = await db.execute(
            select(GeneratedImage).where(GeneratedImage.created_at < cutoff_date)
        )
        old_images = old_images_result.scalars().all()

        deleted_files = 0
        deleted_records = 0

        for image in old_images:
            try:
                if image.local_path and os.path.exists(image.local_path):
                    os.unlink(image.local_path)
                    deleted_files += 1

                await db.delete(image)
                deleted_records += 1

            except Exception as e:
                logger.error(f"Error deleting image {image.id}: {str(e)}")
                continue

        await db.commit()

        return {
            "status": "completed",
            "deleted_files": deleted_files,
            "deleted_records": deleted_records,
            "cutoff_date": cutoff_date.isoformat(),
        }


@celery_app.task(name="health_check")
def health_check_task() -> str:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ Celery worker."""
    return "Celery is working!"


@celery_app.task(name="system_stats")
def system_stats_task() -> Dict[str, Any]:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–∏—Å—Ç–µ–º–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞."""
    try:
        result = _run_async_task(_get_system_stats_async())
        return result

    except Exception as e:
        logger.error(f"Error getting system stats: {str(e)}")
        return {"status": "failed", "error": str(e)}


async def _get_system_stats_async() -> Dict[str, Any]:
    """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å–∏—Å—Ç–µ–º–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏."""
    from sqlalchemy import func
    from app.models.image import GeneratedImage

    async with AsyncSessionLocal() as db:
        # –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–Ω–∏–≥
        books_count = await db.execute(select(func.count(Book.id)))
        total_books = books_count.scalar()

        # –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≥–ª–∞–≤
        chapters_count = await db.execute(select(func.count(Chapter.id)))
        total_chapters = chapters_count.scalar()

        # –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        images_count = await db.execute(select(func.count(GeneratedImage.id)))
        total_images = images_count.scalar()

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º LLM
        from app.services.langextract_processor import LangExtractProcessor
        processor = LangExtractProcessor()
        llm_available = processor.is_available()

        return {
            "status": "operational",
            "total_books": total_books,
            "total_chapters": total_chapters,
            "total_images": total_images,
            "llm_available": llm_available,
            "extraction_mode": "on_demand",
            "timestamp": datetime.now(timezone.utc).isoformat(),
        }
