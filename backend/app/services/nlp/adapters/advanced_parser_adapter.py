"""
–ê–¥–∞–ø—Ç–µ—Ä –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ Advanced Parser –≤ Multi-NLP —Å–∏—Å—Ç–µ–º—É.

–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã AdvancedDescriptionExtractor –≤ —Ñ–æ—Ä–º–∞—Ç ProcessingResult,
—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π —Å Multi-NLP Manager.

–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞:
- AdvancedParserAdapter - –≥–ª–∞–≤–Ω—ã–π –∞–¥–∞–ø—Ç–µ—Ä
- –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç ExtractionResult ‚Üí ProcessingResult
- –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç LLM enrichment (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
- –°–æ–±–∏—Ä–∞–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞
"""

import time
import logging
from typing import Dict, Any, List
from dataclasses import asdict

from ..strategies.base_strategy import ProcessingResult
from ...advanced_parser.extractor import (
    AdvancedDescriptionExtractor,
    ExtractionResult,
)
from ...advanced_parser.config import DescriptionType

logger = logging.getLogger(__name__)


class AdvancedParserAdapter:
    """
    –ê–¥–∞–ø—Ç–µ—Ä –¥–ª—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ Advanced Parser –≤ Multi-NLP —Ñ–æ—Ä–º–∞—Ç.

    –ò–Ω—Ç–µ–≥—Ä–∏—Ä—É–µ—Ç –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π –ø–∞—Ä—Å–µ—Ä –æ–ø–∏—Å–∞–Ω–∏–π (AdvancedDescriptionExtractor)
    —Å Multi-NLP Manager, –ø–æ–∑–≤–æ–ª—è—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –µ–≥–æ –∫–∞–∫ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—É
    —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–º NLP –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞–º (SpaCy, Natasha, Stanza).

    –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:
    - –§–æ–∫—É—Å –Ω–∞ –¥–ª–∏–Ω–Ω—ã–µ –æ–ø–∏—Å–∞–Ω–∏—è (500-3500 —Å–∏–º–≤–æ–ª–æ–≤)
    - –ú–Ω–æ–≥–æ–ø–∞—Ä–∞–≥—Ä–∞—Ñ–Ω—ã–π –∞–Ω–∞–ª–∏–∑
    - 5-—Ñ–∞–∫—Ç–æ—Ä–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
    - –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–µ LLM –æ–±–æ–≥–∞—â–µ–Ω–∏–µ

    Example:
        >>> adapter = AdvancedParserAdapter(enable_enrichment=True)
        >>> result = await adapter.extract_descriptions(chapter_text, chapter_id)
        >>> print(f"–ù–∞–π–¥–µ–Ω–æ {len(result.descriptions)} –æ–ø–∏—Å–∞–Ω–∏–π")
        >>> print(f"–°—Ä–µ–¥–Ω–∏–π score: {result.quality_metrics['average_score']:.2f}")
    """

    def __init__(self, enable_enrichment: bool = True):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–¥–∞–ø—Ç–µ—Ä–∞.

        Args:
            enable_enrichment: –í–∫–ª—é—á–∏—Ç—å LLM enrichment (—Ç—Ä–µ–±—É–µ—Ç API –∫–ª—é—á)
        """
        self.extractor = AdvancedDescriptionExtractor(enable_enrichment=enable_enrichment)
        self.enable_enrichment = enable_enrichment

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
        self.total_conversions = 0
        self.total_conversion_time = 0.0
        self.total_descriptions_converted = 0

        logger.info(
            f"‚úÖ Advanced Parser Adapter initialized "
            f"(enrichment: {enable_enrichment}, "
            f"available: {self.extractor.enricher is not None})"
        )

    async def extract_descriptions(
        self, text: str, chapter_id: str = None
    ) -> ProcessingResult:
        """
        –ò–∑–≤–ª–µ—á—å –æ–ø–∏—Å–∞–Ω–∏—è –∏—Å–ø–æ–ª—å–∑—É—è Advanced Parser –∏ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –≤ ProcessingResult.

        Pipeline:
        1. –ò–∑–≤–ª–µ—á—å –æ–ø–∏—Å–∞–Ω–∏—è —á–µ—Ä–µ–∑ AdvancedDescriptionExtractor
        2. –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å ExtractionResult ‚Üí ProcessingResult
        3. –°–æ–±—Ä–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞
        4. –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏

        Args:
            text: –¢–µ–∫—Å—Ç –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
            chapter_id: –ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –≥–ª–∞–≤—ã (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

        Returns:
            ProcessingResult —Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π —Å Multi-NLP —Å–∏—Å—Ç–µ–º–æ–π
        """
        start_time = time.time()

        # –≠—Ç–∞–ø 1: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –æ–ø–∏—Å–∞–Ω–∏–π —á–µ—Ä–µ–∑ Advanced Parser
        extraction_result = self.extractor.extract(text)

        # –≠—Ç–∞–ø 2: –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ Multi-NLP —Ñ–æ—Ä–º–∞—Ç
        descriptions = self._convert_to_multi_nlp_format(extraction_result)

        # –≠—Ç–∞–ø 3: –†–∞—Å—á–µ—Ç –≤—Ä–µ–º–µ–Ω–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏
        processing_time = time.time() - start_time

        # –û–±–Ω–æ–≤–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        self.total_conversions += 1
        self.total_conversion_time += processing_time
        self.total_descriptions_converted += len(descriptions)

        # –≠—Ç–∞–ø 4: –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ ProcessingResult
        return ProcessingResult(
            descriptions=descriptions,
            processor_results={"advanced_parser": descriptions},
            processing_time=processing_time,
            processors_used=["advanced_parser"],
            quality_metrics=self._extract_quality_metrics(extraction_result),
            recommendations=self._generate_recommendations(extraction_result),
        )

    def _convert_to_multi_nlp_format(
        self, result: ExtractionResult
    ) -> List[Dict[str, Any]]:
        """
        –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å ExtractionResult –≤ Multi-NLP —Ñ–æ—Ä–º–∞—Ç —Å–ø–∏—Å–∫–∞ –æ–ø–∏—Å–∞–Ω–∏–π.

        –§–æ—Ä–º–∞—Ç Multi-NLP –æ–ø–∏—Å–∞–Ω–∏—è:
        {
            "content": str,              # –¢–µ–∫—Å—Ç –æ–ø–∏—Å–∞–Ω–∏—è
            "type": str,                 # –¢–∏–ø: location/character/atmosphere
            "priority_score": float,     # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç (0-3.0+)
            "confidence_score": float,   # –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (0-1)
            "source": str,               # –ò—Å—Ç–æ—á–Ω–∏–∫: "advanced_parser"
            "metadata": dict             # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        }

        Args:
            result: –†–µ–∑—É–ª—å—Ç–∞—Ç –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∏–∑ Advanced Parser

        Returns:
            –°–ø–∏—Å–æ–∫ –æ–ø–∏—Å–∞–Ω–∏–π –≤ Multi-NLP —Ñ–æ—Ä–º–∞—Ç–µ
        """
        descriptions = []

        for desc, score in result.descriptions:
            # –ë–∞–∑–æ–≤–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ
            description = {
                "content": desc.text,
                "type": score.description_type.value,
                "priority_score": score.overall_score * score.priority_weight,
                "confidence_score": score.overall_score,
                "source": "advanced_parser",
                "metadata": {
                    # –°—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
                    "char_length": desc.char_length,
                    "paragraph_count": desc.paragraph_count,
                    "start_paragraph_idx": desc.start_paragraph_idx,
                    "end_paragraph_idx": desc.end_paragraph_idx,
                    # –î–µ—Ç–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ (5 —Ñ–∞–∫—Ç–æ—Ä–æ–≤)
                    "score_breakdown": {
                        "clarity": score.clarity_score,
                        "detail": score.detail_score,
                        "emotional": score.emotional_score,
                        "contextual": score.contextual_score,
                        "literary": score.literary_score,
                    },
                    # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç—ã
                    "priority_weight": score.priority_weight,
                    "is_premium_length": (
                        2000 <= desc.char_length <= 3500
                    ),  # –ü—Ä–µ–º–∏—É–º –¥–ª–∏–Ω–∞ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
                },
            }

            # –î–æ–±–∞–≤–∏—Ç—å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –æ–±–æ–≥–∞—â–µ–Ω–∏—è, –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã
            if hasattr(desc, "enrichment_metadata") and desc.enrichment_metadata:
                description["metadata"]["enrichment"] = desc.enrichment_metadata

            descriptions.append(description)

        return descriptions

    def _extract_quality_metrics(self, result: ExtractionResult) -> Dict[str, float]:
        """
        –ò–∑–≤–ª–µ—á—å –º–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –∏–∑ ExtractionResult.

        –ú–µ—Ç—Ä–∏–∫–∏:
        - total_extracted: –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–∑–≤–ª–µ—á–µ–Ω–æ
        - passed_threshold: –ü—Ä–æ—à–ª–æ –ø–æ—Ä–æ–≥ –∫–∞—á–µ—Å—Ç–≤–∞
        - average_score: –°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
        - enrichment_rate: –ü—Ä–æ—Ü–µ–Ω—Ç –æ–±–æ–≥–∞—â–µ–Ω–Ω—ã—Ö –æ–ø–∏—Å–∞–Ω–∏–π
        - premium_rate: –ü—Ä–æ—Ü–µ–Ω—Ç –ø—Ä–µ–º–∏—É–º –¥–ª–∏–Ω—ã (2000-3500)

        Args:
            result: –†–µ–∑—É–ª—å—Ç–∞—Ç –∏–∑–≤–ª–µ—á–µ–Ω–∏—è

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ –∫–∞—á–µ—Å—Ç–≤–∞
        """
        metrics = {
            "total_extracted": result.total_extracted,
            "passed_threshold": result.passed_threshold,
        }

        if not result.descriptions:
            metrics["average_score"] = 0.0
            metrics["enrichment_rate"] = 0.0
            metrics["premium_rate"] = 0.0
            return metrics

        # –°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
        total_score = sum(score.overall_score for _, score in result.descriptions)
        metrics["average_score"] = total_score / len(result.descriptions)

        # –ü—Ä–æ—Ü–µ–Ω—Ç –æ–±–æ–≥–∞—â–µ–Ω–Ω—ã—Ö
        enriched_count = sum(
            1
            for desc, _ in result.descriptions
            if hasattr(desc, "enrichment_metadata")
            and desc.enrichment_metadata
            and desc.enrichment_metadata.get("llm_enriched", False)
        )
        metrics["enrichment_rate"] = enriched_count / len(result.descriptions)

        # –ü—Ä–æ—Ü–µ–Ω—Ç –ø—Ä–µ–º–∏—É–º –¥–ª–∏–Ω—ã
        premium_count = sum(
            1 for desc, _ in result.descriptions if 2000 <= desc.char_length <= 3500
        )
        metrics["premium_rate"] = premium_count / len(result.descriptions)

        # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Ç–∏–ø–∞–º
        type_distribution = {}
        for _, score in result.descriptions:
            desc_type = score.description_type.value
            type_distribution[desc_type] = type_distribution.get(desc_type, 0) + 1

        metrics["type_distribution"] = type_distribution

        return metrics

    def _generate_recommendations(self, result: ExtractionResult) -> List[str]:
        """
        –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è.

        –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:
        - –ü–æ –∫–∞—á–µ—Å—Ç–≤—É –∏–∑–≤–ª–µ—á–µ–Ω–∏—è
        - –ü–æ –Ω–∞—Å—Ç—Ä–æ–π–∫–µ –ø–æ—Ä–æ–≥–æ–≤
        - –ü–æ LLM enrichment
        - –ü–æ –¥–ª–∏–Ω–µ –æ–ø–∏—Å–∞–Ω–∏–π

        Args:
            result: –†–µ–∑—É–ª—å—Ç–∞—Ç –∏–∑–≤–ª–µ—á–µ–Ω–∏—è

        Returns:
            –°–ø–∏—Å–æ–∫ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
        """
        recommendations = []

        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∫–∞—á–µ—Å—Ç–≤—É
        if result.passed_threshold == 0:
            recommendations.append(
                "‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω–æ –æ–ø–∏—Å–∞–Ω–∏–π –≤—ã—à–µ –ø–æ—Ä–æ–≥–∞ –∫–∞—á–µ—Å—Ç–≤–∞. "
                "–†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ —Å–Ω–∏–∂–µ–Ω–∏–µ –ø–æ—Ä–æ–≥–∞ (min_overall_confidence < 0.65) "
                "–∏–ª–∏ —É–ª—É—á—à–∏—Ç–µ –∫–∞—á–µ—Å—Ç–≤–æ —Ç–µ–∫—Å—Ç–∞."
            )
        elif result.passed_threshold < result.total_extracted * 0.3:
            recommendations.append(
                f"‚ö†Ô∏è –¢–æ–ª—å–∫–æ {result.passed_threshold}/{result.total_extracted} –æ–ø–∏—Å–∞–Ω–∏–π "
                f"–ø—Ä–æ—à–ª–æ –ø–æ—Ä–æ–≥ –∫–∞—á–µ—Å—Ç–≤–∞ ({result.passed_threshold/result.total_extracted:.1%}). "
                f"–¢–µ–∫—Å—Ç –º–æ–∂–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å –º–∞–ª–æ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –æ–ø–∏—Å–∞–Ω–∏–π."
            )

        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –æ–±–æ–≥–∞—â–µ–Ω–∏—é
        stats = result.statistics
        if stats.get("enrichment", {}).get("enabled", False):
            total_attempted = stats["enrichment"].get("total_enriched", 0)
            if total_attempted == 0:
                recommendations.append(
                    "‚ÑπÔ∏è LLM enrichment –≤–∫–ª—é—á–µ–Ω, –Ω–æ –Ω–µ –ø—Ä–∏–º–µ–Ω—è–ª—Å—è. "
                    "–í–æ–∑–º–æ–∂–Ω–æ, –≤—Å–µ –æ–ø–∏—Å–∞–Ω–∏—è –∏–º–µ—é—Ç score < 0.6 –∏–ª–∏ –Ω–µ—Ç API –∫–ª—é—á–∞."
                )
            else:
                avg_time = stats["enrichment"].get("avg_enrichment_time", 0)
                recommendations.append(
                    f"‚úÖ LLM enrichment –∞–∫—Ç–∏–≤–µ–Ω: {total_attempted} –æ–ø–∏—Å–∞–Ω–∏–π –æ–±–æ–≥–∞—â–µ–Ω–æ "
                    f"(—Å—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è: {avg_time:.2f}s)"
                )

        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –¥–ª–∏–Ω–µ
        long_count = len(result.get_long_descriptions(min_chars=2000))
        if long_count > 0:
            recommendations.append(
                f"üéØ –ù–∞–π–¥–µ–Ω–æ {long_count} –ø—Ä–µ–º–∏—É–º –¥–ª–∏–Ω–Ω—ã—Ö –æ–ø–∏—Å–∞–Ω–∏–π (2000+ —Å–∏–º–≤–æ–ª–æ–≤). "
                f"–ü—Ä–∏–æ—Ä–∏—Ç–∏–∑–∏—Ä—É–π—Ç–µ –∏—Ö –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π."
            )
        elif result.passed_threshold > 0:
            # –ï—Å—Ç—å –æ–ø–∏—Å–∞–Ω–∏—è, –Ω–æ –≤—Å–µ –∫–æ—Ä–æ—Ç–∫–∏–µ
            recommendations.append(
                "‚ÑπÔ∏è –í—Å–µ –æ–ø–∏—Å–∞–Ω–∏—è –∫–æ—Ä–æ—á–µ 2000 —Å–∏–º–≤–æ–ª–æ–≤. "
                "–î–ª–∏–Ω–Ω—ã–µ –æ–ø–∏—Å–∞–Ω–∏—è (2000-3500) –¥–∞—é—Ç –ª—É—á—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏."
            )

        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        if result.processing_time > 10.0:
            recommendations.append(
                f"‚ö†Ô∏è –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–Ω—è–ª–∞ {result.processing_time:.1f}s. "
                f"–†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é –¥–ª—è –±–æ–ª—å—à–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤."
            )

        return recommendations

    def get_adapter_statistics(self) -> Dict[str, Any]:
        """
        –ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Ä–∞–±–æ—Ç—ã –∞–¥–∞–ø—Ç–µ—Ä–∞.

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π
        """
        global_stats = self.extractor.get_global_statistics()

        return {
            "adapter": {
                "total_conversions": self.total_conversions,
                "total_conversion_time": self.total_conversion_time,
                "avg_conversion_time": (
                    self.total_conversion_time / self.total_conversions
                    if self.total_conversions > 0
                    else 0
                ),
                "total_descriptions_converted": self.total_descriptions_converted,
                "avg_descriptions_per_conversion": (
                    self.total_descriptions_converted / self.total_conversions
                    if self.total_conversions > 0
                    else 0
                ),
            },
            "extractor": global_stats,
            "enrichment": {
                "enabled": self.enable_enrichment,
                "available": (
                    self.extractor.enricher is not None
                    and self.extractor.enricher.is_available()
                ),
            },
        }

    def reset_statistics(self):
        """–°–±—Ä–æ—Å–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∞–¥–∞–ø—Ç–µ—Ä–∞ –∏ —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä–∞."""
        self.total_conversions = 0
        self.total_conversion_time = 0.0
        self.total_descriptions_converted = 0
        self.extractor.reset_statistics()
