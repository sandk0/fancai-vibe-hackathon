"""
–ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –ø–∞—Ä—Å–µ—Ä –∫–Ω–∏–≥ EPUB –∏ FB2 –¥–ª—è BookReader AI.

–ò—Å–ø–æ–ª—å–∑—É–µ—Ç –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π Table of Contents (TOC) –¥–ª—è –Ω–∞–¥—ë–∂–Ω–æ–≥–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –∫–Ω–∏–≥–∏.
"""

import logging
import os
import re
from dataclasses import dataclass, field
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

from bs4 import BeautifulSoup

# –ë–∏–±–ª–∏–æ—Ç–µ–∫–∏ –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞
try:
    import ebooklib
    from ebooklib import epub

    EBOOKLIB_AVAILABLE = True
except ImportError:
    EBOOKLIB_AVAILABLE = False

try:
    from lxml import etree, html  # noqa: F401

    LXML_AVAILABLE = True
except ImportError:
    LXML_AVAILABLE = False


logger = logging.getLogger(__name__)


# ============================================================================
# DATA MODELS
# ============================================================================


@dataclass
class BookMetadata:
    """–ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∫–Ω–∏–≥–∏."""

    title: str
    author: str = ""
    language: str = "ru"
    genre: str = "other"
    description: str = ""
    isbn: str = ""
    publisher: str = ""
    publish_date: str = ""
    cover_image_data: Optional[bytes] = None
    cover_image_type: str = ""


@dataclass
class BookChapter:
    """–ì–ª–∞–≤–∞ –∫–Ω–∏–≥–∏."""

    number: int
    title: str
    content: str
    html_content: str = ""
    word_count: int = 0

    def __post_init__(self):
        """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–¥—Å—á—ë—Ç —Å–ª–æ–≤ –µ—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω."""
        if self.word_count == 0 and self.content:
            self.word_count = len(self.content.split())


@dataclass
class ParsedBook:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –ø–∞—Ä—Å–∏–Ω–≥–∞ –∫–Ω–∏–≥–∏."""

    metadata: BookMetadata
    chapters: List[BookChapter]
    total_pages: int = 0
    estimated_reading_time: int = 0  # –≤ –º–∏–Ω—É—Ç–∞—Ö
    file_format: str = ""

    def __post_init__(self):
        """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Ä–∞—Å—á—ë—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏."""
        if not self.total_pages or not self.estimated_reading_time:
            total_words = sum(ch.word_count for ch in self.chapters)
            if not self.estimated_reading_time:
                self.estimated_reading_time = max(1, total_words // 200)  # 200 WPM
            if not self.total_pages:
                self.total_pages = max(1, total_words // 250)  # 250 —Å–ª–æ–≤/—Å—Ç—Ä–∞–Ω–∏—Ü—É


@dataclass
class ParserConfig:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø–∞—Ä—Å–µ—Ä–∞."""

    # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –≥–ª–∞–≤—ã (—Å–∏–º–≤–æ–ª–æ–≤)
    min_chapter_length: int = 100

    # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ (—Å–∏–º–≤–æ–ª–æ–≤)
    min_content_length_for_analysis: int = 500

    # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ (–±–∞–π—Ç)
    max_file_size: int = 50 * 1024 * 1024  # 50MB

    # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ (–±–∞–π—Ç)
    min_file_size: int = 1024  # 1KB

    # –°–∫–æ—Ä–æ—Å—Ç—å —á—Ç–µ–Ω–∏—è (—Å–ª–æ–≤ –≤ –º–∏–Ω—É—Ç—É)
    reading_speed_wpm: int = 200

    # –°–ª–æ–≤ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É
    words_per_page: int = 250

    # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å TOC –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω
    prefer_toc: bool = True

    # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –Ω–æ–º–µ—Ä–∞ –≥–ª–∞–≤—ã
    chapter_patterns: List[str] = field(
        default_factory=lambda: [
            r"–≥–ª–∞–≤–∞\s+(\d+)",  # –ì–ª–∞–≤–∞ 1
            r"chapter\s+(\d+)",  # Chapter 1
            r"–≥–ª–∞–≤–∞\s+([ivxlcdm]+)",  # –ì–ª–∞–≤–∞ III (—Ä–∏–º—Å–∫–∏–µ)
        ]
    )

    # –¢–µ–∫—Å—Ç–æ–≤—ã–µ –Ω–æ–º–µ—Ä–∞ –≥–ª–∞–≤ (—Ä—É—Å—Å–∫–∏–π)
    text_number_map: Dict[str, int] = field(
        default_factory=lambda: {
            "–ø–µ—Ä–≤–∞—è": 1,
            "–≤—Ç–æ—Ä–∞—è": 2,
            "—Ç—Ä–µ—Ç—å—è": 3,
            "—á–µ—Ç–≤–µ—Ä—Ç–∞—è": 4,
            "—á–µ—Ç–≤—ë—Ä—Ç–∞—è": 4,
            "–ø—è—Ç–∞—è": 5,
            "—à–µ—Å—Ç–∞—è": 6,
            "—Å–µ–¥—å–º–∞—è": 7,
            "–≤–æ—Å—å–º–∞—è": 8,
            "–¥–µ–≤—è—Ç–∞—è": 9,
            "–¥–µ—Å—è—Ç–∞—è": 10,
            "–æ–¥–∏–Ω–Ω–∞–¥—Ü–∞—Ç–∞—è": 11,
            "–¥–≤–µ–Ω–∞–¥—Ü–∞—Ç–∞—è": 12,
            "—Ç—Ä–∏–Ω–∞–¥—Ü–∞—Ç–∞—è": 13,
            "—á–µ—Ç—ã—Ä–Ω–∞–¥—Ü–∞—Ç–∞—è": 14,
            "–ø—è—Ç–Ω–∞–¥—Ü–∞—Ç–∞—è": 15,
            "—à–µ—Å—Ç–Ω–∞–¥—Ü–∞—Ç–∞—è": 16,
            "—Å–µ–º–Ω–∞–¥—Ü–∞—Ç–∞—è": 17,
            "–≤–æ—Å–µ–º–Ω–∞–¥—Ü–∞—Ç–∞—è": 18,
            "–¥–µ–≤—è—Ç–Ω–∞–¥—Ü–∞—Ç–∞—è": 19,
            "–¥–≤–∞–¥—Ü–∞—Ç–∞—è": 20,
            "one": 1,
            "two": 2,
            "three": 3,
            "four": 4,
            "five": 5,
            "six": 6,
            "seven": 7,
            "eight": 8,
            "nine": 9,
            "ten": 10,
        }
    )


# ============================================================================
# CHAPTER NUMBER EXTRACTOR
# ============================================================================


class ChapterNumberExtractor:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –Ω–æ–º–µ—Ä–∞ –≥–ª–∞–≤ –∏–∑ —Ç–µ–∫—Å—Ç–∞."""

    def __init__(self, config: ParserConfig):
        self.config = config

    def extract(self, text: str, title: str = "") -> Optional[int]:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç –Ω–æ–º–µ—Ä –≥–ª–∞–≤—ã –∏–∑ —Ç–µ–∫—Å—Ç–∞ –∏–ª–∏ –∑–∞–≥–æ–ª–æ–≤–∫–∞.

        –ü—Ä–∏–º–µ—Ä—ã:
            "–ì–ª–∞–≤–∞ 1" -> 1
            "–ì–ª–∞–≤–∞ –ø–µ—Ä–≤–∞—è" -> 1
            "Chapter III" -> 3
        """
        search_text = (title + " " + text[:500]).lower()

        # –ü—Ä–æ–±—É–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã –ø–æ –ø–æ—Ä—è–¥–∫—É
        for pattern in self.config.chapter_patterns:
            match = re.search(pattern, search_text)
            if match:
                number_str = match.group(1)
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∏–º—Å–∫–∏–µ —Ü–∏—Ñ—Ä—ã
                if re.match(r"^[ivxlcdm]+$", number_str):
                    return self._roman_to_int(number_str)
                # –ò–Ω–∞—á–µ –∞—Ä–∞–±—Å–∫–∏–µ
                try:
                    return int(number_str)
                except ValueError:
                    continue

        # –ü—Ä–æ–±—É–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –Ω–æ–º–µ—Ä–∞
        for text_num, num in self.config.text_number_map.items():
            if (
                f"–≥–ª–∞–≤–∞ {text_num}" in search_text
                or f"chapter {text_num}" in search_text
            ):
                return num

        return None

    @staticmethod
    def _roman_to_int(roman: str) -> int:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç —Ä–∏–º—Å–∫–∏–µ —Ü–∏—Ñ—Ä—ã –≤ –∞—Ä–∞–±—Å–∫–∏–µ."""
        roman_values = {"i": 1, "v": 5, "x": 10, "l": 50, "c": 100, "d": 500, "m": 1000}
        result = 0
        prev_value = 0

        for char in reversed(roman.lower()):
            value = roman_values.get(char, 0)
            if value < prev_value:
                result -= value
            else:
                result += value
            prev_value = value

        return result


# ============================================================================
# EPUB PARSER
# ============================================================================


class EPUBParser:
    """–ü–∞—Ä—Å–µ—Ä EPUB —Ñ–∞–π–ª–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º TOC."""

    def __init__(self, config: ParserConfig):
        self.config = config
        self.chapter_extractor = ChapterNumberExtractor(config)

    def parse(self, file_path: str) -> ParsedBook:
        """–ü–∞—Ä—Å–∏—Ç EPUB —Ñ–∞–π–ª."""
        if not EBOOKLIB_AVAILABLE:
            raise ImportError("ebooklib is required for EPUB parsing")

        try:
            book = epub.read_epub(file_path)

            metadata = self._extract_metadata(book)
            chapters = self._extract_chapters(book)

            return ParsedBook(metadata=metadata, chapters=chapters, file_format="epub")

        except Exception as e:
            logger.error(f"Error parsing EPUB: {e}", exc_info=True)
            raise Exception(f"Error parsing EPUB file: {str(e)}")

    def _extract_metadata(self, book) -> BookMetadata:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∏–∑ EPUB."""
        metadata = BookMetadata(title="Unknown")

        try:
            # –ó–∞–≥–æ–ª–æ–≤–æ–∫
            title = book.get_metadata("DC", "title")
            if title:
                metadata.title = title[0][0]

            # –ê–≤—Ç–æ—Ä
            creators = book.get_metadata("DC", "creator")
            if creators:
                metadata.author = creators[0][0]

            # –Ø–∑—ã–∫
            languages = book.get_metadata("DC", "language")
            if languages:
                metadata.language = languages[0][0]

            # –û–ø–∏—Å–∞–Ω–∏–µ
            descriptions = book.get_metadata("DC", "description")
            if descriptions:
                metadata.description = descriptions[0][0]

            # ISBN
            identifiers = book.get_metadata("DC", "identifier")
            for identifier in identifiers:
                if "isbn" in str(identifier[1]).lower():
                    metadata.isbn = identifier[0]
                    break

            # –ò–∑–¥–∞—Ç–µ–ª—å
            publishers = book.get_metadata("DC", "publisher")
            if publishers:
                metadata.publisher = publishers[0][0]

            # –î–∞—Ç–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏
            dates = book.get_metadata("DC", "date")
            if dates:
                metadata.publish_date = dates[0][0]

            # –û–±–ª–æ–∂–∫–∞
            self._extract_cover(book, metadata)

        except Exception as e:
            logger.warning(f"Error extracting EPUB metadata: {e}")

        return metadata

    def _extract_cover(self, book, metadata: BookMetadata):
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –æ–±–ª–æ–∂–∫—É –∫–Ω–∏–≥–∏."""
        # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –ø–æ —Ç–∏–ø—É ITEM_COVER
        for item in book.get_items():
            if item.get_type() == ebooklib.ITEM_COVER:
                metadata.cover_image_data = item.get_content()
                metadata.cover_image_type = item.media_type
                return

        # –ò—â–µ–º –ø–æ –∏–º–µ–Ω–∏ —Å—Ä–µ–¥–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        for item in book.get_items_of_type(ebooklib.ITEM_IMAGE):
            name = item.get_name().lower()
            if "cover" in name:
                metadata.cover_image_data = item.get_content()
                metadata.cover_image_type = item.media_type or "image/jpeg"
                return

        # –ë–µ—Ä—ë–º –ø–µ—Ä–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        images = list(book.get_items_of_type(ebooklib.ITEM_IMAGE))
        if images:
            metadata.cover_image_data = images[0].get_content()
            metadata.cover_image_type = images[0].media_type or "image/jpeg"

    def _extract_chapters(self, book) -> List[BookChapter]:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç –≥–ª–∞–≤—ã –∏–∑ EPUB.

        –°–¢–†–ê–¢–ï–ì–ò–Ø:
        1. –ü—Ä–æ–±—É–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å TOC (Table of Contents) - —Å–∞–º—ã–π –Ω–∞–¥—ë–∂–Ω—ã–π —Å–ø–æ—Å–æ–±
        2. –ï—Å–ª–∏ TOC –ø—É—Å—Ç–æ–π - –∏—Å–ø–æ–ª—å–∑—É–µ–º spine —Å —É–º–Ω–æ–π —ç–≤—Ä–∏—Å—Ç–∏–∫–æ–π
        """
        chapters = []

        # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 1: –ò—Å–ø–æ–ª—å–∑—É–µ–º TOC
        if self.config.prefer_toc:
            chapters = self._extract_chapters_from_toc(book)
            if chapters:
                logger.info(f"‚úÖ Extracted {len(chapters)} chapters from TOC")
                return chapters
            logger.info("üìã TOC is empty or invalid, falling back to spine analysis")

        # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 2: –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º spine
        chapters = self._extract_chapters_from_spine(book)
        logger.info(f"‚úÖ Extracted {len(chapters)} chapters from spine")

        return chapters

    def _extract_chapters_from_toc(self, book) -> List[BookChapter]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –≥–ª–∞–≤—ã –∏—Å–ø–æ–ª—å–∑—É—è –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π TOC."""
        chapters = []

        try:
            toc = book.toc
            if not toc:
                return []

            # TOC –º–æ–∂–µ—Ç –±—ã—Ç—å –≤–ª–æ–∂–µ–Ω–Ω—ã–º, –æ–±—Ö–æ–¥–∏–º —Ä–µ–∫—É—Ä—Å–∏–≤–Ω–æ
            flat_toc = self._flatten_toc(toc)

            logger.info(f"üìö Found {len(flat_toc)} items in TOC")

            for idx, (link, title) in enumerate(flat_toc, start=1):
                try:
                    # –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç –ø–æ —Å—Å—ã–ª–∫–µ
                    content, html_content = self._get_content_by_link(book, link)

                    if not content or len(content) < self.config.min_chapter_length:
                        logger.debug(f"‚è≠Ô∏è  Skipping short TOC item: {title}")
                        continue

                    # –ü—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å –Ω–æ–º–µ—Ä –≥–ª–∞–≤—ã
                    chapter_num = self.chapter_extractor.extract(content, title)

                    # –ï—Å–ª–∏ –Ω–æ–º–µ—Ä –Ω–µ –Ω–∞–π–¥–µ–Ω, —ç—Ç–æ –ù–ï –≥–ª–∞–≤–∞ - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
                    if chapter_num is None:
                        logger.debug(f"‚è≠Ô∏è  Skipping non-chapter TOC item: {title}")
                        continue

                    chapter = BookChapter(
                        number=chapter_num,
                        title=title,
                        content=content,
                        html_content=html_content,
                    )

                    chapters.append(chapter)
                    logger.debug(f"‚úÖ Chapter {chapter_num}: {title[:50]}")

                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è  Error processing TOC item {title}: {e}")
                    continue

            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –Ω–æ–º–µ—Ä–∞–º
            chapters.sort(key=lambda ch: ch.number)

        except Exception as e:
            logger.error(f"‚ùå Error extracting chapters from TOC: {e}")
            return []

        return chapters

    def _flatten_toc(self, toc, depth=0) -> List[Tuple[str, str]]:
        """–†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –æ–±—Ö–æ–¥–∏—Ç –≤–ª–æ–∂–µ–Ω–Ω—ã–π TOC –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–ª–æ—Å–∫–∏–π —Å–ø–∏—Å–æ–∫."""
        flat = []

        for item in toc:
            if isinstance(item, tuple):
                # –≠—Ç–æ (Section, Title) –∏–ª–∏ (Link, Title)
                if hasattr(item[0], "href"):
                    # ebooklib.Link
                    flat.append((item[0].href, item[1]))
                elif isinstance(item[0], list):
                    # –í–ª–æ–∂–µ–Ω–Ω–∞—è —Å–µ–∫—Ü–∏—è
                    flat.extend(self._flatten_toc(item[0], depth + 1))
            elif isinstance(item, list):
                # –í–ª–æ–∂–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫
                flat.extend(self._flatten_toc(item, depth + 1))
            elif hasattr(item, "href"):
                # ebooklib.Link
                flat.append((item.href, getattr(item, "title", "Untitled")))

        return flat

    def _get_content_by_link(self, book, link: str) -> Tuple[str, str]:
        """–ü–æ–ª—É—á–∞–µ—Ç –∫–æ–Ω—Ç–µ–Ω—Ç –ø–æ —Å—Å—ã–ª–∫–µ –∏–∑ TOC."""
        # –£–±–∏—Ä–∞–µ–º —è–∫–æ—Ä—å –∏–∑ —Å—Å—ã–ª–∫–∏
        file_name = link.split("#")[0]

        # –ò—â–µ–º item –ø–æ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
        for item in book.get_items():
            if item.get_name() == file_name or item.get_name().endswith(file_name):
                return self._extract_text_from_item(item)

        return "", ""

    def _extract_chapters_from_spine(self, book) -> List[BookChapter]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –≥–ª–∞–≤—ã –∏–∑ spine —Å —É–º–Ω–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π."""
        chapters: List[BookChapter] = []

        try:
            spine = book.spine
            logger.info(f"üìö EPUB spine has {len(spine)} items")

            for spine_index, spine_item in enumerate(spine):
                try:
                    item_id = spine_item[0]
                    item = book.get_item_with_id(item_id)

                    if not item or item.get_type() != ebooklib.ITEM_DOCUMENT:
                        continue

                    text_content, html_content = self._extract_text_from_item(item)

                    # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∫–æ—Ä–æ—Ç–∫–∏–π –∫–æ–Ω—Ç–µ–Ω—Ç
                    if len(text_content) < self.config.min_chapter_length:
                        logger.debug(f"‚è≠Ô∏è  Skipping short content: {item.get_name()}")
                        continue

                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
                    title = self._extract_title_from_html(html_content)
                    if not title:
                        title = text_content.split("\n")[0].strip()[:100]

                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–æ–º–µ—Ä –≥–ª–∞–≤—ã
                    chapter_num = self.chapter_extractor.extract(text_content, title)

                    # –ï—Å–ª–∏ –Ω–æ–º–µ—Ä –Ω–µ –Ω–∞–π–¥–µ–Ω, –≤–µ—Ä–æ—è—Ç–Ω–æ —ç—Ç–æ –Ω–µ –≥–ª–∞–≤–∞
                    if chapter_num is None:
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —ç–≤—Ä–∏—Å—Ç–∏–∫—É: –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ª–∏ –¥–ª–∏–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç?
                        if (
                            len(text_content)
                            < self.config.min_content_length_for_analysis
                        ):
                            logger.debug(f"‚è≠Ô∏è  Skipping non-chapter: {title[:50]}")
                            continue
                        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ—Ä—è–¥–∫–æ–≤—ã–π –Ω–æ–º–µ—Ä
                        chapter_num = len(chapters) + 1

                    chapter = BookChapter(
                        number=chapter_num,
                        title=title,
                        content=text_content,
                        html_content=html_content,
                    )

                    chapters.append(chapter)
                    logger.debug(f"‚úÖ Chapter {chapter_num}: {title[:50]}")

                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è  Error processing spine item: {e}")
                    continue

            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –Ω–æ–º–µ—Ä–∞–º
            chapters.sort(key=lambda ch: ch.number)

        except Exception as e:
            logger.error(f"‚ùå Error extracting chapters from spine: {e}")

        return chapters

    def _extract_text_from_item(self, item) -> Tuple[str, str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏ HTML –∏–∑ item."""
        try:
            content = item.get_content().decode("utf-8", errors="ignore")
            soup = BeautifulSoup(content, "html.parser")

            # –£–¥–∞–ª—è–µ–º —Å–∫—Ä–∏–ø—Ç—ã –∏ —Å—Ç–∏–ª–∏
            for tag in soup(["script", "style"]):
                tag.decompose()

            # –ü–æ–ª—É—á–∞–µ–º —á–∏—Å—Ç—ã–π —Ç–µ–∫—Å—Ç
            text_content = soup.get_text()
            text_content = re.sub(r"\s+", " ", text_content).strip()

            return text_content, content

        except Exception as e:
            logger.warning(f"Error extracting text from item: {e}")
            return "", ""

    def _extract_title_from_html(self, html_content: str) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∏–∑ HTML."""
        try:
            soup = BeautifulSoup(html_content, "html.parser")
            for tag in ["h1", "h2", "h3", "title"]:
                title_tag = soup.find(tag)
                if title_tag:
                    title = title_tag.get_text().strip()
                    if title:
                        return title
        except Exception as e:
            logger.warning(f"Error extracting chapter title: {e}")
        return ""


# ============================================================================
# FB2 PARSER
# ============================================================================


class FB2Parser:
    """–ü–∞—Ä—Å–µ—Ä FB2 —Ñ–∞–π–ª–æ–≤."""

    def __init__(self, config: ParserConfig):
        self.config = config
        self.namespaces = {"fb": "http://www.gribuser.ru/xml/fictionbook/2.0"}

    def parse(self, file_path: str) -> ParsedBook:
        """–ü–∞—Ä—Å–∏—Ç FB2 —Ñ–∞–π–ª."""
        if not LXML_AVAILABLE:
            raise ImportError("lxml is required for FB2 parsing")

        try:
            # –ß–∏—Ç–∞–µ–º FB2 —Ñ–∞–π–ª
            with open(file_path, "rb") as f:
                content = f.read()

            # –ü–∞—Ä—Å–∏–º XML
            try:
                root = etree.fromstring(content)
            except etree.XMLSyntaxError:
                # –ü—Ä–æ–±—É–µ–º –∏—Å–ø—Ä–∞–≤–∏—Ç—å –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π XML
                content_str = content.decode("utf-8", errors="ignore")
                content_str = re.sub(r"<\?xml[^>]*\?>", "", content_str)
                root = etree.fromstring(content_str.encode("utf-8"))

            metadata = self._extract_metadata(root)
            chapters = self._extract_chapters(root)

            return ParsedBook(metadata=metadata, chapters=chapters, file_format="fb2")

        except Exception as e:
            logger.error(f"Error parsing FB2: {e}", exc_info=True)
            raise Exception(f"Error parsing FB2 file: {str(e)}")

    def _extract_metadata(self, root) -> BookMetadata:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∏–∑ FB2."""
        metadata = BookMetadata(title="Unknown")

        try:
            # –ó–∞–≥–æ–ª–æ–≤–æ–∫
            title_elem = root.find(".//fb:book-title", self.namespaces)
            if title_elem is not None and title_elem.text:
                metadata.title = title_elem.text.strip()

            # –ê–≤—Ç–æ—Ä
            author_elems = root.findall(".//fb:author", self.namespaces)
            if author_elems:
                author_parts = []
                for author in author_elems[:1]:
                    first_name = author.find(".//fb:first-name", self.namespaces)
                    last_name = author.find(".//fb:last-name", self.namespaces)
                    middle_name = author.find(".//fb:middle-name", self.namespaces)

                    if first_name is not None and first_name.text:
                        author_parts.append(first_name.text.strip())
                    if middle_name is not None and middle_name.text:
                        author_parts.append(middle_name.text.strip())
                    if last_name is not None and last_name.text:
                        author_parts.append(last_name.text.strip())

                if author_parts:
                    metadata.author = " ".join(author_parts)

            # –ñ–∞–Ω—Ä
            genre_elem = root.find(".//fb:genre", self.namespaces)
            if genre_elem is not None and genre_elem.text:
                metadata.genre = genre_elem.text.strip()

            # –Ø–∑—ã–∫
            lang_elem = root.find(".//fb:lang", self.namespaces)
            if lang_elem is not None and lang_elem.text:
                metadata.language = lang_elem.text.strip()

            # –û–ø–∏—Å–∞–Ω–∏–µ
            annotation_elem = root.find(".//fb:annotation", self.namespaces)
            if annotation_elem is not None:
                paragraphs = annotation_elem.findall(".//fb:p", self.namespaces)
                if paragraphs:
                    description_parts = [p.text.strip() for p in paragraphs if p.text]
                    metadata.description = " ".join(description_parts)

            # –î–∞—Ç–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏
            date_elem = root.find(".//fb:date", self.namespaces)
            if date_elem is not None and date_elem.text:
                metadata.publish_date = date_elem.text.strip()

        except Exception as e:
            logger.warning(f"Error extracting FB2 metadata: {e}")

        return metadata

    def _extract_chapters(self, root) -> List[BookChapter]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –≥–ª–∞–≤—ã –∏–∑ FB2."""
        chapters = []

        try:
            sections = root.findall(".//fb:section", self.namespaces)

            chapter_number = 1
            for section in sections:
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
                title = ""
                title_elem = section.find(".//fb:title", self.namespaces)
                if title_elem is not None:
                    title_parts = [
                        p.text.strip()
                        for p in title_elem.findall(".//fb:p", self.namespaces)
                        if p.text
                    ]
                    if title_parts:
                        title = " ".join(title_parts)

                if not title:
                    title = f"–ì–ª–∞–≤–∞ {chapter_number}"

                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ
                content_parts = []
                paragraphs = section.findall(".//fb:p", self.namespaces)

                for p in paragraphs:
                    # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø–∞—Ä–∞–≥—Ä–∞—Ñ—ã –∏–∑ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
                    if p.getparent().tag.endswith("title"):
                        continue
                    if p.text:
                        content_parts.append(p.text.strip())

                content = " ".join(content_parts)
                content = re.sub(r"\s+", " ", content).strip()

                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ —Å–µ–∫—Ü–∏–∏
                if len(content) < self.config.min_chapter_length:
                    continue

                chapter = BookChapter(
                    number=chapter_number, title=title, content=content, html_content=""
                )

                chapters.append(chapter)
                chapter_number += 1

        except Exception as e:
            logger.warning(f"Error extracting FB2 chapters: {e}")

        return chapters


# ============================================================================
# MAIN BOOK PARSER
# ============================================================================


class BookParser:
    """–ì–ª–∞–≤–Ω—ã–π –∫–ª–∞—Å—Å –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ –∫–Ω–∏–≥."""

    def __init__(self, config: Optional[ParserConfig] = None):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–∞—Ä—Å–µ—Ä–∞."""
        self.config = config or ParserConfig()

        self.supported_formats = []
        if EBOOKLIB_AVAILABLE:
            self.supported_formats.append("epub")
        if LXML_AVAILABLE:
            self.supported_formats.append("fb2")

        self.epub_parser = EPUBParser(self.config) if EBOOKLIB_AVAILABLE else None
        self.fb2_parser = FB2Parser(self.config) if LXML_AVAILABLE else None

    def is_format_supported(self, file_format: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ–¥–¥–µ—Ä–∂–∫—É —Ñ–æ—Ä–º–∞—Ç–∞."""
        return file_format.lower() in self.supported_formats

    def get_supported_formats(self) -> List[str]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤."""
        return self.supported_formats.copy()

    def detect_format(self, file_path: str) -> str:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞ –∫–Ω–∏–≥–∏."""
        path_obj = Path(file_path)
        extension = path_obj.suffix.lower()

        if extension == ".epub":
            return "epub"
        elif extension == ".fb2":
            return "fb2"
        elif extension == ".xml":
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –ª–∏ XML —Ñ–∞–π–ª–æ–º FB2
            try:
                with open(file_path, "rb") as f:
                    content = f.read(1000)
                    if b"FictionBook" in content:
                        return "fb2"
            except (OSError, IOError) as e:
                logger.warning(f"Error reading file for format detection: {e}")

        return "unknown"

    def parse_book(self, file_path: str) -> ParsedBook:
        """
        –ü–∞—Ä—Å–∏—Ç –∫–Ω–∏–≥—É –∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç –µ—ë —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ.

        Args:
            file_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –∫–Ω–∏–≥–∏

        Returns:
            –û–±—ä–µ–∫—Ç ParsedBook —Å —Å–æ–¥–µ—Ä–∂–∏–º—ã–º –∫–Ω–∏–≥–∏

        Raises:
            ValueError: –ï—Å–ª–∏ —Ñ–æ—Ä–º–∞—Ç –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è
            Exception: –ü—Ä–∏ –æ—à–∏–±–∫–∞—Ö –ø–∞—Ä—Å–∏–Ω–≥–∞
        """
        file_format = self.detect_format(file_path)

        if file_format == "epub":
            if not self.epub_parser:
                raise ImportError("ebooklib is required for EPUB parsing")
            return self.epub_parser.parse(file_path)

        elif file_format == "fb2":
            if not self.fb2_parser:
                raise ImportError("lxml is required for FB2 parsing")
            return self.fb2_parser.parse(file_path)

        else:
            raise ValueError(f"Unsupported book format: {file_format}")

    def validate_book_file(self, file_path: str) -> Dict[str, Any]:
        """
        –í–∞–ª–∏–¥–∏—Ä—É–µ—Ç —Ñ–∞–π–ª –∫–Ω–∏–≥–∏.

        Args:
            file_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏
        """
        result = {
            "is_valid": False,
            "format": "unknown",
            "error": None,
            "file_size": 0,
            "estimated_chapters": 0,
        }

        try:
            if not os.path.exists(file_path):
                result["error"] = "File not found"
                return result

            file_size = os.path.getsize(file_path)
            result["file_size"] = file_size

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
            if file_size > self.config.max_file_size:
                result["error"] = (
                    f"File too large (max {self.config.max_file_size // (1024*1024)}MB)"
                )
                return result

            if file_size < self.config.min_file_size:
                result["error"] = "File too small"
                return result

            file_format = self.detect_format(file_path)
            result["format"] = file_format

            if not self.is_format_supported(file_format):
                result["error"] = f"Unsupported format: {file_format}"
                return result

            # –ü—Ä–æ–±—É–µ–º –ø–∞—Ä—Å–∏—Ç—å –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç–∏
            try:
                parsed_book = self.parse_book(file_path)
                result["is_valid"] = True
                result["estimated_chapters"] = len(parsed_book.chapters)
            except Exception as e:
                result["error"] = f"Parse error: {str(e)}"
                return result

        except Exception as e:
            result["error"] = f"Validation error: {str(e)}"

        return result


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –ø–∞—Ä—Å–µ—Ä–∞
book_parser = BookParser()
