"""
Comprehensive integration tests for Session 6 (Stanza processor activation).

Tests Stanza processor integration with:
- ProcessorRegistry (registration and availability)
- EnsembleVoter (weighted consensus with 4 processors)
- MultiNLPManager (performance benchmarks)
- Strategy Pattern (ENSEMBLE mode with Stanza)

Created: 2025-11-24
QA Report: docs/reports/QA_ANALYSIS_SESSIONS_6-7_2025-11-24.md
"""

import pytest
import pytest_asyncio
import asyncio
import time
from datetime import datetime
from typing import List, Dict, Any

from app.services.multi_nlp_manager import MultiNLPManager
from app.services.nlp.strategies import ProcessingMode
from app.services.nlp.components.processor_registry import ProcessorRegistry
from app.services.nlp.components.config_loader import ConfigLoader
from app.services.nlp.components.ensemble_voter import EnsembleVoter
from app.core.config import settings


# Sample Russian literary text for testing
SAMPLE_TEXT = """
–°—Ç–∞—Ä—ã–π –∑–∞–º–æ–∫ –≤–æ–∑–≤—ã—à–∞–ª—Å—è –Ω–∞ –≤—ã—Å–æ–∫–æ–º —Ö–æ–ª–º–µ, –æ–∫—Ä—É–∂–µ–Ω–Ω—ã–π –≥—É—Å—Ç—ã–º –ª–µ—Å–æ–º.
–ï–≥–æ –≤–µ–ª–∏—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –±–∞—à–Ω–∏ –∫–∞—Å–∞–ª–∏—Å—å –æ–±–ª–∞–∫–æ–≤, –∞ –º—Ä–∞—á–Ω—ã–µ —Å—Ç–µ–Ω—ã —Ö—Ä–∞–Ω–∏–ª–∏
–º–Ω–æ–∂–µ—Å—Ç–≤–æ —Ç–∞–π–Ω. –ú–æ–ª–æ–¥–æ–π –∫–Ω—è–∑—å –ê–ª–µ–∫—Å–µ–π —Å—Ç–æ—è–ª —É –æ–∫–Ω–∞, –µ–≥–æ —Ç–µ–º–Ω—ã–µ –≥–ª–∞–∑–∞
—Å–º–æ—Ç—Ä–µ–ª–∏ –≤–¥–∞–ª—å. –î–ª–∏–Ω–Ω—ã–µ —á–µ—Ä–Ω—ã–µ –≤–æ–ª–æ—Å—ã —Ä–∞–∑–≤–µ–≤–∞–ª–∏—Å—å –Ω–∞ –≤–µ—Ç—Ä—É.
–ê—Ç–º–æ—Å—Ñ–µ—Ä–∞ –±—ã–ª–∞ –Ω–∞–ø—Ä—è–∂–µ–Ω–Ω–æ–π –∏ —Ç–∞–∏–Ω—Å—Ç–≤–µ–Ω–Ω–æ–π, –≤–æ–∑–¥—É—Ö –ø–∞—Ö –¥—Ä–µ–≤–Ω–æ—Å—Ç—å—é
–∏ –∑–∞–±—ã—Ç—ã–º–∏ –ª–µ–≥–µ–Ω–¥–∞–º–∏.
"""

# Larger text for performance testing (~2000 chars)
LARGE_SAMPLE_TEXT = """
–°—Ç–∞—Ä–∏–Ω–Ω–æ–µ –ø–æ–º–µ—Å—Ç—å–µ —Ä–∞—Å–ø–æ–ª–∞–≥–∞–ª–æ—Å—å –Ω–∞ –≤–µ—Ä—à–∏–Ω–µ —Ö–æ–ª–º–∞, –æ–∫—Ä—É–∂–µ–Ω–Ω–æ–µ –≤–µ–∫–æ–≤—ã–º–∏ –¥—É–±–∞–º–∏ –∏ –µ–ª—è–º–∏.
–ú–∞—Å—Å–∏–≤–Ω—ã–µ –∫–∞–º–µ–Ω–Ω—ã–µ —Å—Ç–µ–Ω—ã, –ø–æ–∫—Ä—ã—Ç—ã–µ –ø–ª—é—â–æ–º –∏ –º—Ö–æ–º, —Å–≤–∏–¥–µ—Ç–µ–ª—å—Å—Ç–≤–æ–≤–∞–ª–∏ –æ –º–Ω–æ–≥–æ–≤–µ–∫–æ–≤–æ–π –∏—Å—Ç–æ—Ä–∏–∏.
–í—ã—Å–æ–∫–∏–µ —É–∑–∫–∏–µ –æ–∫–Ω–∞ —Å –≤–∏—Ç—Ä–∞–∂–Ω—ã–º–∏ —Å—Ç–µ–∫–ª–∞–º–∏ –º–µ—Ä—Ü–∞–ª–∏ —Ä–∞–∑–Ω–æ—Ü–≤–µ—Ç–Ω—ã–º–∏ –±–ª–∏–∫–∞–º–∏ –≤ –ª—É—á–∞—Ö –∑–∞—Ö–æ–¥—è—â–µ–≥–æ —Å–æ–ª–Ω—Ü–∞.

–ì–ª–∞–≤–Ω–∞—è –±–∞—à–Ω—è –≤–æ–∑–≤—ã—à–∞–ª–∞—Å—å –Ω–∞–¥ –≤—Å–µ–º –∫–æ–º–ø–ª–µ–∫—Å–æ–º, –µ–µ –æ—Å—Ç—Ä—ã–π —à–ø–∏–ª—å —É–ø–∏—Ä–∞–ª—Å—è –≤ –æ–±–ª–∞–∫–∞.
–° —ç—Ç–æ–π –≤—ã—Å–æ—Ç—ã –æ—Ç–∫—Ä—ã–≤–∞–ª—Å—è –≤–µ–ª–∏–∫–æ–ª–µ–ø–Ω—ã–π –≤–∏–¥ –Ω–∞ –æ–∫—Ä–µ—Å—Ç–Ω–æ—Å—Ç–∏: –±–µ—Å–∫—Ä–∞–π–Ω–∏–µ –ª–µ—Å–∞, –∏–∑–≤–∏–ª–∏—Å—Ç—É—é —Ä–µ–∫—É
–∏ –¥–∞–ª–µ–∫–∏–µ –≥–æ—Ä—ã –Ω–∞ –≥–æ—Ä–∏–∑–æ–Ω—Ç–µ. –í–µ—Ç–µ—Ä —Å–≤–∏—Å—Ç–µ–ª –º–µ–∂–¥—É –∑—É–±—Ü–∞–º–∏ –∫—Ä–µ–ø–æ—Å—Ç–Ω—ã—Ö —Å—Ç–µ–Ω, —Å–æ–∑–¥–∞–≤–∞—è
–∂—É—Ç–∫–æ–≤–∞—Ç—É—é –º–µ–ª–æ–¥–∏—é, –∫–æ—Ç–æ—Ä–∞—è —ç—Ö–æ–º —Ä–∞–∑–Ω–æ—Å–∏–ª–∞—Å—å –ø–æ –ø—É—Å—Ç—ã–Ω–Ω—ã–º –∫–æ—Ä–∏–¥–æ—Ä–∞–º.

–ö–Ω—è–∑—å –ê–ª–µ–∫—Å–∞–Ω–¥—Ä –ù–∏–∫–æ–ª–∞–µ–≤–∏—á —Å—Ç–æ—è–ª —É –æ–∫–Ω–∞ –±–æ–ª—å—à–æ–≥–æ –∑–∞–ª–∞. –ï–≥–æ –≤—ã—Å–æ–∫–∞—è —Ñ–∏–≥—É—Ä–∞ –≤—ã–¥–µ–ª—è–ª–∞—Å—å
–Ω–∞ —Ñ–æ–Ω–µ —É–≥–∞—Å–∞—é—â–µ–≥–æ —Å–≤–µ—Ç–∞. –¢–µ–º–Ω—ã–µ –≥–ª—É–±–æ–∫–∏–µ –≥–ª–∞–∑–∞ —Å–º–æ—Ç—Ä–µ–ª–∏ –≤–¥–∞–ª—å —Å –≤—ã—Ä–∞–∂–µ–Ω–∏–µ–º –≥–ª—É–±–æ–∫–æ–π
–∑–∞–¥—É–º—á–∏–≤–æ—Å—Ç–∏. –î–ª–∏–Ω–Ω—ã–µ —á–µ—Ä–Ω—ã–µ –≤–æ–ª–æ—Å—ã —Å –ø—Ä–æ—Å–µ–¥—å—é –∫–∞—Å–∞–ª–∏—Å—å –ø–ª–µ—á. –ò–∑—è—â–Ω—ã–µ —Ä—É–∫–∏ —Å –¥–ª–∏–Ω–Ω—ã–º–∏
–ø–∞–ª—å—Ü–∞–º–∏ –Ω–µ—Ä–≤–Ω–æ —Å–∂–∏–º–∞–ª–∏ –ø–æ–¥–æ–∫–æ–Ω–Ω–∏–∫.

–ú–æ–ª–æ–¥–∞—è –≥—Ä–∞—Ñ–∏–Ω—è –ï–ª–∏–∑–∞–≤–µ—Ç–∞ –≤–æ—à–ª–∞ –≤ –∑–∞–ª. –ï–µ –ª–µ–≥–∫–∞—è –ø–æ—Ö–æ–¥–∫–∞ –µ–¥–≤–∞ —Å–ª—ã—à–∞–ª–∞—Å—å –Ω–∞ –∫–∞–º–µ–Ω–Ω–æ–º –ø–æ–ª—É.
–ó–æ–ª–æ—Ç–∏—Å—Ç—ã–µ –≤–æ–ª–æ—Å—ã —Å—Ç—Ä—É–∏–ª–∏—Å—å –ø–æ –ø–ª–µ—á–∞–º, –æ–±—Ä–∞–º–ª—è—è –Ω–µ–∂–Ω–æ–µ –ª–∏—Ü–æ —Å –±–æ–ª—å—à–∏–º–∏ –≥–æ–ª—É–±—ã–º–∏ –≥–ª–∞–∑–∞–º–∏.
–ë–ª–µ–¥–Ω–∞—è –∫–æ–∂–∞ –∫–∞–∑–∞–ª–∞—Å—å –ø–æ—á—Ç–∏ –ø—Ä–æ–∑—Ä–∞—á–Ω–æ–π –≤ –º—è–≥–∫–æ–º —Å–≤–µ—Ç–µ —Å–≤–µ—á–µ–π. –ò–∑—è—â–Ω–∞—è —Ñ–∏–≥—É—Ä–∞ –ø–æ–¥—á–µ—Ä–∫–∏–≤–∞–ª–∞—Å—å
–∏–∑—ã—Å–∫–∞–Ω–Ω—ã–º –ø–ª–∞—Ç—å–µ–º —Ç–µ–º–Ω–æ-—Å–∏–Ω–µ–≥–æ –±–∞—Ä—Ö–∞—Ç–∞.

–ê—Ç–º–æ—Å—Ñ–µ—Ä–∞ –≤ –∑–∞–ª–µ –±—ã–ª–∞ —Ç–æ—Ä–∂–µ—Å—Ç–≤–µ–Ω–Ω–æ–π –∏ –Ω–µ–º–Ω–æ–≥–æ –º—Ä–∞—á–Ω–æ–π. –¢—è–∂–µ–ª—ã–µ –ø–æ—Ä—Ç—å–µ—Ä—ã –∏–∑ —Ç–µ–º–Ω–æ–≥–æ –±–∞—Ä—Ö–∞—Ç–∞
–∑–∞–∫—Ä—ã–≤–∞–ª–∏ –æ–∫–Ω–∞, –ø—Ä–∏–≥–ª—É—à–∞—è –ø–æ—Å–ª–µ–¥–Ω–∏–µ –ª—É—á–∏ —Å–æ–ª–Ω—Ü–∞. –°—Ç–∞—Ä–∏–Ω–Ω—ã–µ –≥–æ–±–µ–ª–µ–Ω—ã –Ω–∞ —Å—Ç–µ–Ω–∞—Ö –∏–∑–æ–±—Ä–∞–∂–∞–ª–∏
—Å—Ü–µ–Ω—ã –æ—Ö–æ—Ç—ã –∏ –±–∞—Ç–∞–ª–∏–π. –ú–∞—Å—Å–∏–≤–Ω–∞—è –ª—é—Å—Ç—Ä–∞ —Å —Ö—Ä—É—Å—Ç–∞–ª—å–Ω—ã–º–∏ –ø–æ–¥–≤–µ—Å–∫–∞–º–∏ –æ—Ç–±—Ä–∞—Å—ã–≤–∞–ª–∞ –ø—Ä–∏—á—É–¥–ª–∏–≤—ã–µ
—Ç–µ–Ω–∏ –Ω–∞ –≤—ã—Å–æ–∫–∏–π –ø–æ—Ç–æ–ª–æ–∫ —Å –ø–æ–∑–æ–ª–æ—á–µ–Ω–Ω–æ–π –ª–µ–ø–Ω–∏–Ω–æ–π.

–ö–∞–º–∏–Ω –∏–∑ —á–µ—Ä–Ω–æ–≥–æ –º—Ä–∞–º–æ—Ä–∞ –∑–∞–Ω–∏–º–∞–ª –≤—Å—é —Ç–æ—Ä—Ü–µ–≤—É—é —Å—Ç–µ–Ω—É. –í –Ω–µ–º –ø–æ—Ç—Ä–µ—Å–∫–∏–≤–∞–ª–∏ –¥—É–±–æ–≤—ã–µ –ø–æ–ª–µ–Ω—å—è,
—Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω—è—è –ø—Ä–∏—è—Ç–Ω–æ–µ —Ç–µ–ø–ª–æ –∏ –∞—Ä–æ–º–∞—Ç –¥—Ä–µ–≤–µ—Å–∏–Ω—ã. –ù–∞–¥ –∫–∞–º–∏–Ω–æ–º –≤–∏—Å–µ–ª —Å—Ç–∞—Ä–∏–Ω–Ω—ã–π –ø–æ—Ä—Ç—Ä–µ—Ç
–≤ –∑–æ–ª–æ—á–µ–Ω–æ–π —Ä–∞–º–µ - —Å—É—Ä–æ–≤—ã–π –ø—Ä–µ–¥–æ–∫ —Å –ø—Ä–æ–Ω–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–º –≤–∑–≥–ª—è–¥–æ–º —Ç–µ–º–Ω—ã—Ö –≥–ª–∞–∑.
""" * 2  # –£–¥–≤–∞–∏–≤–∞–µ–º –¥–ª—è ~2000 chars


@pytest.mark.asyncio
class TestStanzaIntegration:
    """
    Comprehensive integration tests for Stanza processor activation (Session 6).

    Tests cover critical gaps identified in QA analysis:
    1. ProcessorRegistry integration
    2. 4-processor ensemble performance (<4s)
    3. EnsembleVoter weighted consensus
    4. Model availability and error handling
    5. Performance with real Russian text
    """

    @pytest_asyncio.fixture
    async def manager(self):
        """Create and initialize MultiNLPManager with all processors."""
        mgr = MultiNLPManager()
        await mgr.initialize()
        return mgr

    @pytest_asyncio.fixture
    def ensemble_voter(self):
        """Create EnsembleVoter instance."""
        return EnsembleVoter(voting_threshold=0.6)

    # ========================================================================================
    # Test 1: CRITICAL - ProcessorRegistry Integration
    # ========================================================================================

    async def test_stanza_registered_in_processor_registry(self, manager):
        """
        CRITICAL: Verify Stanza processor is correctly registered in ProcessorRegistry.

        Gap addressed: No test verified Stanza loads with ProcessorRegistry
        Expected: Stanza should be in available processors with weight 0.8
        """
        # Get status from registry
        processor_registry = manager.processor_registry
        status = processor_registry.get_status()

        # Assert Stanza is registered
        assert "stanza" in status["available_processors"], (
            f"‚ùå Stanza not in available processors. "
            f"Available: {status['available_processors']}"
        )

        # Verify Stanza details
        stanza_details = status["processor_details"]["stanza"]
        assert stanza_details["loaded"] is True, (
            "‚ùå Stanza marked as not loaded"
        )
        assert stanza_details["available"] is True, (
            "‚ùå Stanza marked as not available"
        )

        # Verify Stanza configuration
        stanza_config = stanza_details["config"]
        assert stanza_config["enabled"] is True, (
            "‚ùå Stanza not enabled in config"
        )
        assert stanza_config["weight"] == 0.8, (
            f"‚ùå Stanza weight incorrect. Expected 0.8, got {stanza_config['weight']}"
        )
        assert stanza_config["confidence_threshold"] >= 0.3, (
            "‚ùå Stanza confidence threshold too low"
        )

        # Get actual processor instance
        stanza_processor = processor_registry.get_processor("stanza")
        assert stanza_processor is not None, "‚ùå Cannot retrieve Stanza processor instance"
        assert stanza_processor.is_available() is True, (
            "‚ùå Stanza processor not available"
        )

        print(f"‚úÖ Stanza registered correctly in ProcessorRegistry")
        print(f"   - Weight: {stanza_config['weight']}")
        print(f"   - Confidence threshold: {stanza_config['confidence_threshold']}")
        print(f"   - Available processors: {status['available_processors']}")

    # ========================================================================================
    # Test 2: CRITICAL - 4-Processor Ensemble Performance
    # ========================================================================================

    async def test_4processor_ensemble_performance(self, manager):
        """
        CRITICAL: Verify 4-processor ensemble (SpaCy, Natasha, Stanza, GLiNER) maintains <4s.

        Gap addressed: Performance regression test missing
        Expected: Processing time <4.0s for standard text (~2000 chars)

        Performance targets:
        - SpaCy: ~200ms
        - Natasha: ~250ms
        - Stanza: ~800ms (dependency parsing)
        - GLiNER: ~500ms
        - Parallel total: ~800ms (longest processor)
        - With voting overhead: 1.2-2.5s acceptable
        """
        start_time = time.time()

        # Process with ENSEMBLE mode (all 4 processors)
        result = await manager.extract_descriptions(
            LARGE_SAMPLE_TEXT,
            chapter_id="perf_test_4proc",
            mode=ProcessingMode.ENSEMBLE
        )

        elapsed = time.time() - start_time

        # CRITICAL: Performance must be <4.0s
        assert elapsed < 4.0, (
            f"‚ùå PERFORMANCE REGRESSION: 4-processor ensemble took {elapsed:.2f}s (limit: 4.0s). "
            f"Processors used: {result.processors_used}. "
            f"This indicates Stanza added unacceptable overhead."
        )

        # Verify all 4 processors were used (or at least 3 if one failed gracefully)
        num_processors = len(result.processors_used)
        assert num_processors >= 3, (
            f"‚ùå Insufficient processors used: {num_processors}. "
            f"Expected 4 (SpaCy, Natasha, Stanza, GLiNER). "
            f"Used: {result.processors_used}"
        )

        # Check that Stanza was actually used
        assert "stanza" in result.processors_used, (
            f"‚ùå Stanza not used in ensemble mode. "
            f"Processors used: {result.processors_used}"
        )

        # Verify quality maintained
        assert len(result.descriptions) > 0, (
            "‚ùå No descriptions extracted - quality check failed"
        )

        # Performance tiers
        if elapsed < 2.0:
            performance_tier = "üöÄ EXCELLENT"
        elif elapsed < 3.0:
            performance_tier = "‚úÖ GOOD"
        elif elapsed < 4.0:
            performance_tier = "‚ö†Ô∏è  ACCEPTABLE"
        else:
            performance_tier = "‚ùå SLOW"

        print(f"‚úÖ 4-processor ensemble performance: {performance_tier}")
        print(f"   - Processing time: {elapsed:.2f}s / 4.0s limit")
        print(f"   - Descriptions: {len(result.descriptions)}")
        print(f"   - Processors used: {result.processors_used}")
        print(f"   - Descriptions/sec: {len(result.descriptions)/elapsed:.1f}")
        print(f"   - Quality metrics: {result.quality_metrics}")

    # ========================================================================================
    # Test 3: CRITICAL - Ensemble Voting with Stanza Weight
    # ========================================================================================

    async def test_ensemble_voting_includes_stanza_weight(self, manager):
        """
        CRITICAL: Verify ensemble voting correctly applies Stanza weight (0.8).

        Gap addressed: Voting logic not verified with real Stanza output
        Expected: Stanza votes weighted at 0.8 (vs SpaCy 1.0, Natasha 1.2, GLiNER 1.0)
        """
        # Process with ENSEMBLE mode
        result = await manager.extract_descriptions(
            SAMPLE_TEXT,
            chapter_id="voting_test",
            mode=ProcessingMode.ENSEMBLE
        )

        # Verify ensemble mode was used
        assert result.processors_used, "‚ùå No processors used"

        # Check for ensemble voting indicators in results
        ensemble_descriptions = []
        for desc in result.descriptions:
            # Look for ensemble metadata
            if desc.get("processing_method") == "ensemble":
                ensemble_descriptions.append(desc)

            # Check for consensus indicators
            if "consensus_ratio" in desc or "sources" in desc:
                ensemble_descriptions.append(desc)

        # If no explicit ensemble metadata, check that results came from multiple sources
        if not ensemble_descriptions:
            # Collect all sources
            all_sources = set()
            for desc in result.descriptions:
                source = desc.get("source", "")
                if source:
                    all_sources.add(source)

            # Should have multiple sources (indicating voting happened)
            assert len(all_sources) > 1, (
                f"‚ùå Only one source found: {all_sources}. "
                "Ensemble voting may not be working."
            )
            print(f"   - Sources detected: {all_sources}")
        else:
            # Verify ensemble metadata
            print(f"   - Ensemble descriptions: {len(ensemble_descriptions)}/{len(result.descriptions)}")

            # Check for quality indicators
            quality_indicators = {}
            for desc in ensemble_descriptions:
                quality = desc.get("quality_indicator", "unknown")
                quality_indicators[quality] = quality_indicators.get(quality, 0) + 1

            print(f"   - Quality distribution: {quality_indicators}")

        # Verify Stanza contributed to results
        stanza_mentions = sum(
            1 for desc in result.descriptions
            if "stanza" in desc.get("source", "").lower() or
               "stanza" in str(desc.get("sources", [])).lower()
        )

        assert stanza_mentions > 0, (
            "‚ùå Stanza did not contribute to any descriptions. "
            f"Sources found: {[desc.get('source') for desc in result.descriptions[:5]]}"
        )

        print(f"‚úÖ Ensemble voting includes Stanza weight (0.8)")
        print(f"   - Stanza contributions: {stanza_mentions} descriptions")
        print(f"   - Total descriptions: {len(result.descriptions)}")
        print(f"   - Processors: {result.processors_used}")

    # ========================================================================================
    # Test 4: HIGH - Stanza Model Availability
    # ========================================================================================

    async def test_stanza_model_availability(self, manager):
        """
        HIGH: Verify Stanza model is downloaded and available.

        Gap addressed: Model download not tested (unit tests mocked)
        Expected: Real Stanza model available at /tmp/stanza_resources
        """
        import os
        import stanza

        # Check if Stanza resources directory exists
        stanza_dir = os.environ.get("STANZA_RESOURCES_DIR", "/tmp/stanza_resources")

        if os.path.exists(stanza_dir):
            print(f"‚úÖ Stanza resources directory exists: {stanza_dir}")

            # Check directory contents
            if os.path.isdir(stanza_dir):
                ru_dir = os.path.join(stanza_dir, "ru")
                if os.path.exists(ru_dir):
                    contents = os.listdir(ru_dir)
                    print(f"   - Russian model files: {len(contents)} files/dirs")
        else:
            print(f"‚ö†Ô∏è  Stanza resources directory not found: {stanza_dir}")

        # Verify processor is actually available
        processor_registry = manager.processor_registry
        stanza_processor = processor_registry.get_processor("stanza")
        assert stanza_processor is not None, "‚ùå Stanza processor not registered"

        # Check availability
        is_available = stanza_processor.is_available()
        assert is_available is True, (
            "‚ùå Stanza processor not available. "
            "Model may not be downloaded. "
            f"Run: python -c 'import stanza; stanza.download(\"ru\")'"
        )

        # Verify model is loaded
        assert stanza_processor.loaded is True, "‚ùå Stanza model not loaded"
        assert stanza_processor.model is not None, "‚ùå Stanza model is None"

        print(f"‚úÖ Stanza model available and loaded")
        print(f"   - Processor available: {is_available}")
        print(f"   - Model loaded: {stanza_processor.loaded}")

    # ========================================================================================
    # Test 5: MEDIUM - Stanza Performance with Real Russian Text
    # ========================================================================================

    async def test_stanza_performance_with_real_text(self, manager):
        """
        MEDIUM: Test Stanza performance with real Russian literary text.

        Gap addressed: No performance benchmarks for Stanza alone
        Expected: ~800ms for dependency parsing on ~2000 char text
        """
        processor_registry = manager.processor_registry
        stanza_processor = processor_registry.get_processor("stanza")
        assert stanza_processor is not None, "‚ùå Stanza processor not available"

        # Small text test
        start_time = time.time()
        small_result = await stanza_processor.extract_descriptions(
            SAMPLE_TEXT,
            chapter_id="stanza_perf_small"
        )
        small_elapsed = time.time() - start_time

        # Large text test
        start_time = time.time()
        large_result = await stanza_processor.extract_descriptions(
            LARGE_SAMPLE_TEXT,
            chapter_id="stanza_perf_large"
        )
        large_elapsed = time.time() - start_time

        # Performance assertions
        assert small_elapsed < 2.0, (
            f"‚ùå Stanza too slow on small text: {small_elapsed:.2f}s (limit: 2.0s)"
        )
        assert large_elapsed < 5.0, (
            f"‚ùå Stanza too slow on large text: {large_elapsed:.2f}s (limit: 5.0s)"
        )

        # Quality checks
        assert len(small_result) > 0, "‚ùå No descriptions from small text"
        assert len(large_result) > len(small_result), (
            "‚ùå Large text should produce more descriptions than small text"
        )

        # Check for dependency parsing features
        dependency_descriptions = [
            desc for desc in large_result
            if desc.get("source") == "stanza_dependency"
        ]

        # Check for NER features
        ner_descriptions = [
            desc for desc in large_result
            if desc.get("source") == "stanza_ner"
        ]

        print(f"‚úÖ Stanza performance with real text:")
        print(f"   Small text ({len(SAMPLE_TEXT)} chars):")
        print(f"     - Time: {small_elapsed:.2f}s")
        print(f"     - Descriptions: {len(small_result)}")
        print(f"   Large text ({len(LARGE_SAMPLE_TEXT)} chars):")
        print(f"     - Time: {large_elapsed:.2f}s")
        print(f"     - Descriptions: {len(large_result)}")
        print(f"     - Dependency parsing: {len(dependency_descriptions)}")
        print(f"     - NER: {len(ner_descriptions)}")

    # ========================================================================================
    # Test 6: MEDIUM - Fallback Behavior When Stanza Unavailable
    # ========================================================================================

    async def test_ensemble_fallback_without_stanza(self, manager):
        """
        MEDIUM: Test graceful degradation if Stanza fails to load.

        Gap addressed: Fallback untested
        Expected: System works with 3 processors if Stanza unavailable

        Note: This test checks that the system can handle processor unavailability.
        We can't easily simulate Stanza failure without mocking, but we can verify
        the fallback logic by checking processor availability handling.
        """
        # Get current processor status
        status = await manager.get_processor_status()

        available_count = len(status["available_processors"])

        # System should work with at least 2 processors
        assert available_count >= 2, (
            f"‚ùå Insufficient processors: {available_count}. "
            "Multi-NLP requires at least 2 processors for ensemble voting."
        )

        # Process text
        result = await manager.extract_descriptions(
            SAMPLE_TEXT,
            chapter_id="fallback_test",
            mode=ProcessingMode.ENSEMBLE
        )

        # Should get results even if not all processors available
        assert result is not None, "‚ùå No result returned"
        assert len(result.descriptions) > 0, "‚ùå No descriptions extracted"

        # Check recommendations for any warnings about processor availability
        recommendations = result.recommendations
        if available_count < 4:
            print(f"‚ö†Ô∏è  Only {available_count}/4 processors available")
            print(f"   Available: {status['available_processors']}")
        else:
            print(f"‚úÖ All 4 processors available")

        print(f"   - Processors used: {result.processors_used}")
        print(f"   - Descriptions: {len(result.descriptions)}")
        print(f"   - Quality: {result.quality_metrics}")

    # ========================================================================================
    # Test 7: MEDIUM - Weighted Consensus Algorithm Validation
    # ========================================================================================

    async def test_weighted_consensus_algorithm(self, ensemble_voter, manager):
        """
        MEDIUM: Verify weighted consensus algorithm correctly weights Stanza at 0.8.

        Gap addressed: No direct test of EnsembleVoter with real processor weights
        Expected: Stanza weight (0.8) correctly applied in voting calculations
        """
        # Create mock processor results for testing
        # Simulate descriptions from all 4 processors
        spacy_desc = {
            "content": "–°—Ç–∞—Ä—ã–π –∑–∞–º–æ–∫ –Ω–∞ —Ö–æ–ª–º–µ",
            "type": "location",
            "priority_score": 0.7,
            "confidence_score": 0.8,
            "source": "spacy_ner"
        }

        natasha_desc = {
            "content": "–°—Ç–∞—Ä—ã–π –∑–∞–º–æ–∫ –Ω–∞ —Ö–æ–ª–º–µ",
            "type": "location",
            "priority_score": 0.75,
            "confidence_score": 0.85,
            "source": "natasha_ner"
        }

        stanza_desc = {
            "content": "–°—Ç–∞—Ä—ã–π –∑–∞–º–æ–∫ –Ω–∞ —Ö–æ–ª–º–µ",
            "type": "location",
            "priority_score": 0.8,
            "confidence_score": 0.9,
            "source": "stanza_dependency"
        }

        gliner_desc = {
            "content": "–°—Ç–∞—Ä—ã–π –∑–∞–º–æ–∫ –Ω–∞ —Ö–æ–ª–º–µ",
            "type": "location",
            "priority_score": 0.72,
            "confidence_score": 0.82,
            "source": "gliner_ner"
        }

        processor_results = {
            "spacy": [spacy_desc],
            "natasha": [natasha_desc],
            "stanza": [stanza_desc],
            "gliner": [gliner_desc]
        }

        # Get actual processors for weights
        processor_registry = manager.processor_registry
        processors = processor_registry.get_all_processors()

        # Apply voting
        voted_results = ensemble_voter.vote(processor_results, processors)

        # Should produce 1 consensus result (all describe same location)
        assert len(voted_results) > 0, "‚ùå No results from voting"

        # Check consensus metadata
        consensus_result = voted_results[0]
        assert "consensus_ratio" in consensus_result, (
            "‚ùå No consensus_ratio in result"
        )
        assert "sources" in consensus_result, (
            "‚ùå No sources in result"
        )

        # Should have all 4 sources
        sources = consensus_result["sources"]
        assert len(sources) == 4, (
            f"‚ùå Expected 4 sources, got {len(sources)}: {sources}"
        )

        # Consensus ratio should be high (all agreed)
        consensus_ratio = consensus_result["consensus_ratio"]
        assert consensus_ratio >= 0.6, (
            f"‚ùå Low consensus ratio: {consensus_ratio}"
        )

        print(f"‚úÖ Weighted consensus algorithm validated:")
        print(f"   - Sources: {sources}")
        print(f"   - Consensus ratio: {consensus_ratio:.2f}")
        print(f"   - Quality indicator: {consensus_result.get('quality_indicator')}")
        print(f"   - Ensemble boosted: {consensus_result.get('ensemble_boosted')}")

    # ========================================================================================
    # Test 8: MEDIUM - All Processing Modes with Stanza
    # ========================================================================================

    async def test_all_processing_modes_with_stanza(self, manager):
        """
        MEDIUM: Verify Stanza works correctly in all processing modes.

        Gap addressed: Only ensemble mode tested previously
        Expected: Stanza participates in PARALLEL, SEQUENTIAL, and ADAPTIVE modes
        """
        modes_to_test = [
            ProcessingMode.PARALLEL,
            ProcessingMode.SEQUENTIAL,
            ProcessingMode.ENSEMBLE,
            ProcessingMode.ADAPTIVE
        ]

        results = {}

        for mode in modes_to_test:
            start_time = time.time()

            result = await manager.extract_descriptions(
                SAMPLE_TEXT,
                chapter_id=f"mode_test_{mode.value}",
                mode=mode
            )

            elapsed = time.time() - start_time

            results[mode.value] = {
                "time": elapsed,
                "descriptions": len(result.descriptions),
                "processors": result.processors_used,
                "stanza_used": "stanza" in result.processors_used
            }

            # All modes should produce results
            assert result is not None, f"‚ùå No result from {mode.value} mode"
            assert len(result.descriptions) > 0, (
                f"‚ùå No descriptions from {mode.value} mode"
            )

            print(f"‚úÖ {mode.value} mode:")
            print(f"   - Time: {elapsed:.2f}s")
            print(f"   - Descriptions: {len(result.descriptions)}")
            print(f"   - Processors: {result.processors_used}")
            print(f"   - Stanza used: {'‚úì' if results[mode.value]['stanza_used'] else '‚úó'}")

        # Stanza should be used in at least some modes
        stanza_usage_count = sum(
            1 for r in results.values() if r["stanza_used"]
        )
        assert stanza_usage_count > 0, (
            "‚ùå Stanza not used in any processing mode"
        )

        print(f"\n‚úÖ Stanza used in {stanza_usage_count}/{len(modes_to_test)} modes")


# ========================================================================================
# Standalone Performance Benchmark (Optional)
# ========================================================================================

@pytest.mark.asyncio
@pytest.mark.benchmark(group="stanza-integration")
async def test_stanza_benchmark():
    """
    Optional benchmark test for detailed performance profiling.

    Run with: pytest -v -s -k benchmark
    """
    manager = MultiNLPManager()
    await manager.initialize()

    iterations = 5
    times = []

    print("\n" + "="*80)
    print("STANZA INTEGRATION PERFORMANCE BENCHMARK")
    print("="*80)

    for i in range(iterations):
        start = time.time()

        result = await manager.extract_descriptions(
            LARGE_SAMPLE_TEXT,
            chapter_id=f"benchmark_{i}",
            mode=ProcessingMode.ENSEMBLE
        )

        elapsed = time.time() - start
        times.append(elapsed)

        print(f"Iteration {i+1}: {elapsed:.3f}s ({len(result.descriptions)} descriptions)")

    avg_time = sum(times) / len(times)
    min_time = min(times)
    max_time = max(times)

    print("="*80)
    print(f"Results ({iterations} iterations):")
    print(f"  Average: {avg_time:.3f}s")
    print(f"  Min:     {min_time:.3f}s")
    print(f"  Max:     {max_time:.3f}s")
    print(f"  Target:  <4.000s")
    print(f"  Status:  {'‚úÖ PASS' if avg_time < 4.0 else '‚ùå FAIL'}")
    print("="*80)

    assert avg_time < 4.0, (
        f"‚ùå Average performance {avg_time:.3f}s exceeds 4.0s limit"
    )


if __name__ == "__main__":
    # Run tests
    pytest.main([__file__, "-v", "-s"])
