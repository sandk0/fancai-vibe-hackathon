# –ü–ª–∞–Ω –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π Perplexity AI

## –î–∞—Ç–∞: 11 –Ω–æ—è–±—Ä—è 2025
## –°—Ç–∞—Ç—É—Å: –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω, –≥–æ—Ç–æ–≤—ã –∫ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏

---

## –†–µ–∑—é–º–µ –∞–Ω–∞–ª–∏–∑–∞ Perplexity AI

Perplexity AI –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–ª –∑–∞–¥–∞—á—É –ø–∞—Ä—Å–∏–Ω–≥–∞ –¥–ª–∏–Ω–Ω—ã—Ö –æ–ø–∏—Å–∞–Ω–∏–π –∏–∑ —Ä—É—Å—Å–∫–æ–π –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä—ã –∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏–ª **–∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤–∞–∂–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏** –ø–æ —É–ª—É—á—à–µ–Ω–∏—é –Ω–∞—à–µ–π —Å–∏—Å—Ç–µ–º—ã.

### ‚úÖ –ü–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç–∏ –Ω–∞—à–µ–≥–æ –ø–æ–¥—Ö–æ–¥–∞

1. **Multi-NLP ensemble** - Perplexity –ü–û–î–¢–í–ï–†–ñ–î–ê–ï–¢ –Ω–∞—à –ø–æ–¥—Ö–æ–¥ –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–æ–≤
2. **Paragraph-based parsing** - –Ω–∞—à –ø–æ–¥—Ö–æ–¥ –£–ù–ò–ö–ê–õ–¨–ù–´–ô, –∞–Ω–∞–ª–æ–≥–æ–≤ –Ω–µ—Ç
3. **Natasha + SpaCy + Stanza** - –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –±–∞–∑–æ–≤—ã–π —Å—Ç–µ–∫
4. **–§–æ–∫—É—Å –Ω–∞ –¥–ª–∏–Ω–Ω—ã—Ö –æ–ø–∏—Å–∞–Ω–∏—è—Ö** - –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞–µ—Ç—Å—è –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç—å

### üöÄ –ù–æ–≤—ã–µ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –Ω–∞—Ö–æ–¥–∫–∏

| –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç | –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç | –£–ª—É—á—à–µ–Ω–∏–µ | F1 Score |
|-----------|-----------|-----------|----------|
| **DeepPavlov** | P0 | NER –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ | 0.94-0.97 (vs 0.85-0.90 Natasha) |
| **LangExtract (Google)** | P0 | –î–µ—Ç–∞–ª—å–Ω—ã–µ –æ–ø–∏—Å–∞–Ω–∏—è | –†–µ–≤–æ–ª—é—Ü–∏—è! |
| **GLiNER** | P1 | Zero-shot –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ | –ì–∏–±–∫–æ—Å—Ç—å |
| **Dependency Parsing** | P1 | –°–∏–Ω—Ç–∞–∫—Å–∏—á–µ—Å–∫–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã | +20-30% —Ç–æ—á–Ω–æ—Å—Ç—å |

---

## Priority 0 (–ö–†–ò–¢–ò–ß–ù–û) - –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –æ—Å–Ω–æ–≤–Ω—ã—Ö –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤

### 1. DeepPavlov - 4-–π –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –≤ Multi-NLP —Å–∏—Å—Ç–µ–º–µ

**–ó–∞—á–µ–º**: F1 0.94-0.97 –¥–ª—è PERSON (–Ω–∞ 7-12% –≤—ã—à–µ Natasha)

**–£—Å—Ç–∞–Ω–æ–≤–∫–∞**:
```bash
pip install deeppavlov
python -m deeppavlov install entity_extraction_ru
```

**–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –≤ Multi-NLP**:
```python
# backend/app/services/deeppavlov_processor.py
from deeppavlov import build_model
from typing import List, Dict

class DeepPavlovProcessor:
    """
    4-–π –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –≤ Multi-NLP —Å–∏—Å—Ç–µ–º–µ.

    –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:
    - F1 0.94-0.97 –¥–ª—è PERSON (–≤—ã—à–µ –≤—Å–µ—Ö)
    - –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä-based –º–æ–¥–µ–ª—å
    - Relation Extraction
    - Entity Linking —Å Wikidata

    –ù–µ–¥–æ—Å—Ç–∞—Ç–∫–∏:
    - –¢—Ä–µ–±—É–µ—Ç GPU (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ CPU)
    - –ú–µ–¥–ª–µ–Ω–Ω–µ–µ —á–µ–º Natasha
    """

    def __init__(self):
        self.ner_model = build_model('entity_extraction_ru')
        self.relation_model = build_model('relation_extraction_ru')

    def extract_entities(self, text: str) -> List[Dict]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å—É—â–Ω–æ—Å—Ç–µ–π —Å –≤—ã—Å–æ–∫–æ–π —Ç–æ—á–Ω–æ—Å—Ç—å—é."""
        entities = self.ner_model([text])
        return entities

    def extract_relations(self, text: str) -> List[Dict]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –æ—Ç–Ω–æ—à–µ–Ω–∏–π –º–µ–∂–¥—É —Å—É—â–Ω–æ—Å—Ç—è–º–∏."""
        relations = self.relation_model([text])
        return relations
```

**–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ Multi-NLP Manager**:
```python
# –î–æ–±–∞–≤–∏—Ç—å –≤ backend/app/services/multi_nlp_manager.py
from .deeppavlov_processor import DeepPavlovProcessor

class MultiNLPManager:
    def __init__(self):
        self.processors = {
            "spacy": SpacyProcessor(),
            "natasha": NatashaProcessor(),
            "stanza": StanzaProcessor(),
            "deeppavlov": DeepPavlovProcessor(),  # NEW!
        }

        # –û–±–Ω–æ–≤–∏—Ç—å –≤–µ—Å–∞
        self.weights = {
            "spacy": 1.0,
            "natasha": 1.2,
            "stanza": 0.8,
            "deeppavlov": 1.5,  # –°–∞–º—ã–π –≤—ã—Å–æ–∫–∏–π –≤–µ—Å –∏–∑-–∑–∞ –∫–∞—á–µ—Å—Ç–≤–∞!
        }
```

**–í—Ä–µ–º—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏**: 1-2 –¥–Ω—è

---

### 2. LangExtract (Google) - –§–∏–Ω–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ–ø–∏—Å–∞–Ω–∏–π

**–ó–∞—á–µ–º**: –†–ï–í–û–õ–Æ–¶–ò–û–ù–ù–û–ï —Ä–µ—à–µ–Ω–∏–µ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–µ—Ç–∞–ª—å–Ω—ã—Ö –æ–ø–∏—Å–∞–Ω–∏–π —Å LLM

**–£—Å—Ç–∞–Ω–æ–≤–∫–∞**:
```bash
pip install langextract
```

**–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞**:
```
–ù–∞—à –ø–∞—Ä—Å–µ—Ä (paragraph-based)
    ‚Üì –ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ (500-3500 —Å–∏–º–≤–æ–ª–æ–≤)
    ‚Üì
LangExtract + LLM (Gemini/GPT-4)
    ‚Üì –û–±–æ–≥–∞—â–∞–µ—Ç –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É–µ—Ç –æ–ø–∏—Å–∞–Ω–∏—è
    ‚Üì
–§–∏–Ω–∞–ª—å–Ω—ã–µ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –æ–ø–∏—Å–∞–Ω–∏—è –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
```

**–†–µ–∞–ª–∏–∑–∞—Ü–∏—è**:
```python
# backend/app/services/advanced_parser/llm_enrichment.py
import langextract as lx

class LLMDescriptionEnricher:
    """
    –§–∏–Ω–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ–ø–∏—Å–∞–Ω–∏–π —Å –ø–æ–º–æ—â—å—é LLM.

    –ü—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è –¢–û–õ–¨–ö–û –∫ –æ—Ç–æ–±—Ä–∞–Ω–Ω—ã–º –Ω–∞—à–∏–º –ø–∞—Ä—Å–µ—Ä–æ–º –æ–ø–∏—Å–∞–Ω–∏—è–º
    –¥–ª—è –æ–±–æ–≥–∞—â–µ–Ω–∏—è –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–∏—è.

    –ù–µ –∑–∞–º–µ–Ω—è–µ—Ç –Ω–∞—à –ø–∞—Ä—Å–µ—Ä, –∞ –î–û–ü–û–õ–ù–Ø–ï–¢ –µ–≥–æ!
    """

    def __init__(self, model_id: str = "gemini-2.0-flash-exp"):
        self.model_id = model_id

    def enrich_description(
        self,
        description_text: str,
        description_type: str  # location, character, atmosphere
    ) -> Dict:
        """
        –û–±–æ–≥–∞—Ç–∏—Ç—å –æ–ø–∏—Å–∞–Ω–∏–µ —á–µ—Ä–µ–∑ LLM.

        Args:
            description_text: –¢–µ–∫—Å—Ç –æ–ø–∏—Å–∞–Ω–∏—è –æ—Ç –Ω–∞—à–µ–≥–æ –ø–∞—Ä—Å–µ—Ä–∞
            description_type: –¢–∏–ø –æ–ø–∏—Å–∞–Ω–∏—è

        Returns:
            –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –æ–±–æ–≥–∞—â–µ–Ω–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ
        """

        prompt_templates = {
            "location": """
            –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –æ–ø–∏—Å–∞–Ω–∏–µ –ª–æ–∫–∞—Ü–∏–∏ –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É–π –µ–≥–æ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:

            –¢–µ–∫—Å—Ç: {text}

            –ò–∑–≤–ª–µ–∫–∏:
            1. –û—Å–Ω–æ–≤–Ω—ã–µ –≤–∏–∑—É–∞–ª—å–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã (–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞, –ø—Ä–∏—Ä–æ–¥–∞, –æ–±—ä–µ–∫—Ç—ã)
            2. –¶–≤–µ—Ç–∞ –∏ –æ—Å–≤–µ—â–µ–Ω–∏–µ
            3. –ê—Ç–º–æ—Å—Ñ–µ—Ä—É –∏ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ
            4. –ü—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ (—Ä–∞–∑–º–µ—Ä, —Ñ–æ—Ä–º–∞, —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω–∏–µ)
            5. –ö–ª—é—á–µ–≤—ã–µ –¥–µ—Ç–∞–ª–∏ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏

            –§–æ—Ä–º–∞—Ç: JSON —Å –ø–æ–ª—è–º–∏ visual_elements, colors, lighting, atmosphere, spatial, key_details
            """,

            "character": """
            –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –æ–ø–∏—Å–∞–Ω–∏–µ –ø–µ—Ä—Å–æ–Ω–∞–∂–∞ –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É–π –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:

            –¢–µ–∫—Å—Ç: {text}

            –ò–∑–≤–ª–µ–∫–∏:
            1. –§–∏–∑–∏—á–µ—Å–∫–∞—è –≤–Ω–µ—à–Ω–æ—Å—Ç—å (–ª–∏—Ü–æ, —Ñ–∏–≥—É—Ä–∞, —Ä–æ—Å—Ç)
            2. –û–¥–µ–∂–¥–∞ –∏ –∞–∫—Å–µ—Å—Å—É–∞—Ä—ã
            3. –¶–≤–µ—Ç–∞ (–≤–æ–ª–æ—Å—ã, –≥–ª–∞–∑–∞, –∫–æ–∂–∞, –æ–¥–µ–∂–¥–∞)
            4. –ü–æ–∑–∞ –∏ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ –ª–∏—Ü–∞
            5. –û–∫—Ä—É–∂–∞—é—â–∞—è –æ–±—Å—Ç–∞–Ω–æ–≤–∫–∞

            –§–æ—Ä–º–∞—Ç: JSON —Å –ø–æ–ª—è–º–∏ appearance, clothing, colors, pose, expression, setting
            """,

            "atmosphere": """
            –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –æ–ø–∏—Å–∞–Ω–∏–µ –∞—Ç–º–æ—Å—Ñ–µ—Ä—ã –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É–π –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:

            –¢–µ–∫—Å—Ç: {text}

            –ò–∑–≤–ª–µ–∫–∏:
            1. –ù–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ –∏ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π —Ç–æ–Ω
            2. –í–∏–∑—É–∞–ª—å–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã –∞—Ç–º–æ—Å—Ñ–µ—Ä—ã (—Å–≤–µ—Ç, —Ç–µ–Ω–∏, –ø–æ–≥–æ–¥–∞)
            3. –°–µ–Ω—Å–æ—Ä–Ω—ã–µ –¥–µ—Ç–∞–ª–∏ (–∑–≤—É–∫–∏, –∑–∞–ø–∞—Ö–∏, —Ç–∞–∫—Ç–∏–ª—å–Ω—ã–µ –æ—â—É—â–µ–Ω–∏—è)
            4. –í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ (–≤—Ä–µ–º—è —Å—É—Ç–æ–∫, —Å–µ–∑–æ–Ω)
            5. –°–∏–º–≤–æ–ª–∏—á–µ—Å–∫–∏–µ —ç–ª–µ–º–µ–Ω—Ç—ã

            –§–æ—Ä–º–∞—Ç: JSON —Å –ø–æ–ª—è–º–∏ mood, visual_atmosphere, sensory, temporal, symbolic
            """
        }

        prompt = prompt_templates.get(description_type, prompt_templates["location"])
        prompt = prompt.format(text=description_text)

        result = lx.extract(
            text_or_documents=description_text,
            prompt_description=prompt,
            model_id=self.model_id
        )

        return result
```

**–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å AdvancedDescriptionExtractor**:
```python
# –î–æ–±–∞–≤–∏—Ç—å –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π —ç—Ç–∞–ø –≤ extractor.py
class AdvancedDescriptionExtractor:
    def __init__(self, config, use_llm_enrichment=False):
        self.use_llm_enrichment = use_llm_enrichment
        if use_llm_enrichment:
            self.llm_enricher = LLMDescriptionEnricher()

    def extract(self, text: str):
        # ... —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π pipeline ...

        # –≠—Ç–∞–ø 6 (–ù–û–í–´–ô): LLM –æ–±–æ–≥–∞—â–µ–Ω–∏–µ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        if self.use_llm_enrichment:
            enriched = []
            for desc, score in ranked:
                enriched_data = self.llm_enricher.enrich_description(
                    desc.text,
                    score.description_type.value
                )
                desc.metadata['llm_enrichment'] = enriched_data
                enriched.append((desc, score))
            ranked = enriched

        return result
```

**–í—Ä–µ–º—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏**: 2-3 –¥–Ω—è

---

### 3. Dependency Parsing - –ü–æ–∏—Å–∫ –æ–ø–∏—Å–∞—Ç–µ–ª—å–Ω—ã—Ö –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–π

**–ó–∞—á–µ–º**: –ù–∞–π—Ç–∏ –ø—Ä–∏–ª–∞–≥–∞—Ç–µ–ª—å–Ω—ã–µ + —Å—É—â–µ—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–µ, —Å–ª–æ–∂–Ω—ã–µ —Å–∏–Ω—Ç–∞–∫—Å–∏—á–µ—Å–∫–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã

**–†–µ–∞–ª–∏–∑–∞—Ü–∏—è –≤ ParagraphSegmenter**:
```python
# –î–æ–±–∞–≤–∏—Ç—å –≤ paragraph_segmenter.py
import spacy

class ParagraphSegmenter:
    def __init__(self, config):
        # ... existing init ...
        self.nlp = spacy.load("ru_core_news_lg")  # –î–ª—è dependency parsing

    def _extract_descriptive_phrases(self, text: str) -> List[str]:
        """
        –ò–∑–≤–ª–µ—á—å –æ–ø–∏—Å–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—Ä–∞–∑—ã —á–µ—Ä–µ–∑ dependency parsing.

        –ü–∞—Ç—Ç–µ—Ä–Ω—ã:
        - ADJ + NOUN (–∫—Ä–∞—Å–∏–≤—ã–π –¥–æ–º)
        - ADJ + ADJ + NOUN (–±–æ–ª—å—à–æ–π –∫—Ä–∞—Å–∏–≤—ã–π –¥–æ–º)
        - NOUN + PREP + NOUN (–¥–æ–º –Ω–∞ —Ö–æ–ª–º–µ)
        """
        doc = self.nlp(text)
        phrases = []

        # –ü–∞—Ç—Ç–µ—Ä–Ω 1: –ü—Ä–∏–ª–∞–≥–∞—Ç–µ–ª—å–Ω–æ–µ + –°—É—â–µ—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ–µ
        for token in doc:
            if token.pos_ == "NOUN":
                # –ù–∞–π—Ç–∏ –≤—Å–µ –ø—Ä–∏–ª–∞–≥–∞—Ç–µ–ª—å–Ω—ã–µ, –º–æ–¥–∏—Ñ–∏—Ü–∏—Ä—É—é—â–∏–µ —ç—Ç–æ —Å—É—â–µ—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ–µ
                adjectives = [child for child in token.children if child.pos_ == "ADJ"]
                if adjectives:
                    phrase = " ".join([adj.text for adj in adjectives] + [token.text])
                    phrases.append(phrase)

        # –ü–∞—Ç—Ç–µ—Ä–Ω 2: –°—É—â–µ—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ–µ + –ü—Ä–µ–¥–ª–æ–≥ + –°—É—â–µ—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ–µ
        for token in doc:
            if token.pos_ == "NOUN":
                for child in token.children:
                    if child.dep_ == "case" and child.pos_ == "ADP":
                        # –ù–∞–π—Ç–∏ –∑–∞–≤–∏—Å–∏–º–æ–µ —Å—É—â–µ—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ–µ
                        for subchild in token.head.children:
                            if subchild.pos_ == "NOUN":
                                phrase = f"{token.text} {child.text} {subchild.text}"
                                phrases.append(phrase)

        return phrases

    def _calculate_descriptiveness(self, text: str) -> float:
        """–û–±–Ω–æ–≤–ª–µ–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ —Å —É—á–µ—Ç–æ–º dependency parsing."""
        # ... —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∫–æ–¥ ...

        # –ù–û–í–´–ô —Ñ–∞–∫—Ç–æ—Ä: –æ–ø–∏—Å–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—Ä–∞–∑—ã (15%)
        descriptive_phrases = self._extract_descriptive_phrases(text)
        phrase_score = min(len(descriptive_phrases) / 5.0, 1.0)
        score += 0.15 * phrase_score

        return min(score, 1.0)
```

**–í—Ä–µ–º—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏**: 1 –¥–µ–Ω—å

---

## Priority 1 (–í–ê–ñ–ù–û) - –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —É–ª—É—á—à–µ–Ω–∏—è

### 4. GLiNER - Zero-shot –∫–∞—Ç–µ–≥–æ—Ä–∏–∏

**–ó–∞—á–µ–º**: –ì–∏–±–∫–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –Ω–µ—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π ("–∞—Ç–º–æ—Å—Ñ–µ—Ä–∞", "—ç–º–æ—Ü–∏—è", "–Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ")

**–£—Å—Ç–∞–Ω–æ–≤–∫–∞**:
```bash
pip install gliner
```

**–†–µ–∞–ª–∏–∑–∞—Ü–∏—è**:
```python
# backend/app/services/gliner_processor.py
from gliner import GLiNER

class GLiNERProcessor:
    """
    5-–π –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –¥–ª—è zero-shot –∏–∑–≤–ª–µ—á–µ–Ω–∏—è.

    –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏:
    - –ù–µ —Ç—Ä–µ–±—É–µ—Ç –æ–±—É—á–µ–Ω–∏—è
    - –ú–æ–∂–Ω–æ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Å–≤–æ–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
    - –û—Ç–ª–∏—á–Ω–æ –¥–ª—è –∞—Ç–º–æ—Å—Ñ–µ—Ä—ã –∏ —ç–º–æ—Ü–∏–π
    """

    def __init__(self):
        self.model = GLiNER.from_pretrained("urchade/gliner_multilingual_base")

    def extract_custom_entities(self, text: str) -> Dict:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–∞—Å—Ç–æ–º–Ω—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π."""
        labels = [
            "–ø–µ—Ä—Å–æ–Ω–∞–∂",
            "–ª–æ–∫–∞—Ü–∏—è",
            "–∞—Ç–º–æ—Å—Ñ–µ—Ä–∞",  # –ù–û–í–û–ï!
            "—ç–º–æ—Ü–∏—è",     # –ù–û–í–û–ï!
            "–Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ", # –ù–û–í–û–ï!
            "–≤—Ä–µ–º—è —Å—É—Ç–æ–∫",
            "–ø–æ–≥–æ–¥–∞",
            "—Ü–≤–µ—Ç",
            "–æ—Å–≤–µ—â–µ–Ω–∏–µ"
        ]

        entities = self.model.predict_entities(text, labels)

        # –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∞—Ç—å –ø–æ —Ç–∏–ø–∞–º
        grouped = {}
        for entity in entities:
            label = entity["label"]
            if label not in grouped:
                grouped[label] = []
            grouped[label].append(entity["text"])

        return grouped
```

**–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –≤ MultiFactorConfidenceScorer**:
```python
# –î–æ–±–∞–≤–∏—Ç—å –≤ confidence_scorer.py
class MultiFactorConfidenceScorer:
    def __init__(self, config):
        # ... existing init ...
        self.gliner = GLiNERProcessor()

    def _calculate_visual_richness(self, text: str) -> float:
        """–û–±–Ω–æ–≤–ª–µ–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ —Å GLiNER."""
        # ... —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∫–æ–¥ ...

        # –ù–û–í–´–ô –ø–æ–¥—Ñ–∞–∫—Ç–æ—Ä: –∫–∞—Å—Ç–æ–º–Ω—ã–µ –≤–∏–∑—É–∞–ª—å–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ (20%)
        custom_entities = self.gliner.extract_custom_entities(text)

        visual_categories = ["—Ü–≤–µ—Ç", "–æ—Å–≤–µ—â–µ–Ω–∏–µ", "–ø–æ–≥–æ–¥–∞", "–≤—Ä–µ–º—è —Å—É—Ç–æ–∫"]
        found_categories = sum(1 for cat in visual_categories if cat in custom_entities)

        custom_score = found_categories / len(visual_categories)
        score += 0.2 * custom_score

        return min(score, 1.0)
```

**–í—Ä–µ–º—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏**: 1-2 –¥–Ω—è

---

### 5. Coreference Resolution - –û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π

**–ó–∞—á–µ–º**: –°–≤—è–∑—ã–≤–∞—Ç—å —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –æ–¥–Ω–æ–≥–æ –ø–µ—Ä—Å–æ–Ω–∞–∂–∞ —á–µ—Ä–µ–∑ –º–µ—Å—Ç–æ–∏–º–µ–Ω–∏—è

**–ü–æ–¥—Ö–æ–¥—ã**:

1. **–ü—Ä–æ—Å—Ç–æ–π (regex-based)**:
```python
# –î–æ–±–∞–≤–∏—Ç—å –≤ boundary_detector.py
class DescriptionBoundaryDetector:
    def _resolve_coreference_simple(self, current_text: str, next_text: str) -> bool:
        """
        –ü—Ä–æ—Å—Ç–æ–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ –∫–æ—Ä–µ—Ñ–µ—Ä–µ–Ω—Ü–∏–∏ —á–µ—Ä–µ–∑ –º–µ—Å—Ç–æ–∏–º–µ–Ω–∏—è.
        """
        pronouns = ["–æ–Ω", "–æ–Ω–∞", "–æ–Ω–æ", "–æ–Ω–∏", "–µ–≥–æ", "–µ—ë", "–∏—Ö"]

        # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å, –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è –ª–∏ —Å–ª–µ–¥—É—é—â–∏–π —Ç–µ–∫—Å—Ç —Å –º–µ—Å—Ç–æ–∏–º–µ–Ω–∏—è
        first_word = next_text.strip().split()[0].lower()
        if first_word in pronouns:
            # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å, –µ—Å—Ç—å –ª–∏ –≤ —Ç–µ–∫—É—â–µ–º —Ç–µ–∫—Å—Ç–µ –ø–æ–¥—Ö–æ–¥—è—â–∞—è —Å—É—â–Ω–æ—Å—Ç—å
            # (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)
            return True

        return False
```

2. **–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π (DeepPavlov neuralcoref)**:
```python
# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å DeepPavlov –¥–ª—è –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω–æ–π –∫–æ—Ä–µ—Ñ–µ—Ä–µ–Ω—Ü–∏–∏
from deeppavlov import build_model

class CoreferenceResolver:
    def __init__(self):
        # DeepPavlov –Ω–µ –∏–º–µ–µ—Ç –≥–æ—Ç–æ–≤–æ–π —Ä—É—Å—Å–∫–æ–π –º–æ–¥–µ–ª–∏ coref
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ–º–±–∏–Ω–∞—Ü–∏—é NER + –ø—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞
        self.ner_model = build_model('entity_extraction_ru')

    def resolve_entities(self, texts: List[str]) -> Dict:
        """
        –†–∞–∑—Ä–µ—à–∏—Ç—å –∫–æ—Ä–µ—Ñ–µ—Ä–µ–Ω—Ü–∏—é –º–µ–∂–¥—É –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞–º–∏.
        """
        # –ò–∑–≤–ª–µ—á—å –≤—Å–µ —Å—É—â–Ω–æ—Å—Ç–∏
        all_entities = []
        for text in texts:
            entities = self.ner_model([text])
            all_entities.extend(entities)

        # –°–≥—Ä—É–ø–ø–∏—Ä–æ–≤–∞—Ç—å –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ —Å—É—â–Ω–æ—Å—Ç–∏
        # ... –ª–æ–≥–∏–∫–∞ –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏ ...

        return grouped_entities
```

**–í—Ä–µ–º—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏**: 2-3 –¥–Ω—è

---

## Priority 2 (–û–ü–¶–ò–û–ù–ê–õ–¨–ù–û) - Advanced Features

### 6. Renard - –ì—Ä–∞—Ñ—ã –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π

**–ó–∞—á–µ–º**: –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –æ—Ç–Ω–æ—à–µ–Ω–∏–π –º–µ–∂–¥—É –ø–µ—Ä—Å–æ–Ω–∞–∂–∞–º–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ –¥–ª—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∏)

**–£—Å—Ç–∞–Ω–æ–≤–∫–∞**:
```bash
pip install renard-pipeline
```

**–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ**:
```python
from renard.pipeline import Pipeline
from renard.pipeline.tokenization import NLTKTokenizer
from renard.pipeline.ner import NLTKNamedEntityRecognizer

pipeline = Pipeline([
    NLTKTokenizer(),
    NLTKNamedEntityRecognizer(),
    # ... other steps
])

graph = pipeline(book_text)
# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –æ—Ç–Ω–æ—à–µ–Ω–∏–π –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π
```

**–í—Ä–µ–º—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏**: 2-3 –¥–Ω—è (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ)

---

## –û–±–Ω–æ–≤–ª–µ–Ω–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Å –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–µ–π Perplexity

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    INPUT: Chapter Text                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ STAGE 1: Paragraph Segmentation (–Ω–∞—à —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –ø–æ–¥—Ö–æ–¥!)       ‚îÇ
‚îÇ  ‚Ä¢ ParagraphSegmenter                                           ‚îÇ
‚îÇ  ‚Ä¢ Dependency Parsing –¥–ª—è –æ–ø–∏—Å–∞—Ç–µ–ª—å–Ω—ã—Ö —Ñ—Ä–∞–∑ (–ù–û–í–û–ï –æ—Ç Perplexity)‚îÇ
‚îÇ  ‚Ä¢ –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è: DESCRIPTION, NARRATIVE, DIALOG, META          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ STAGE 2: Boundary Detection (–Ω–∞—à —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –ø–æ–¥—Ö–æ–¥!)           ‚îÇ
‚îÇ  ‚Ä¢ DescriptionBoundaryDetector                                  ‚îÇ
‚îÇ  ‚Ä¢ Coreference Resolution (–ù–û–í–û–ï –æ—Ç Perplexity)                 ‚îÇ
‚îÇ  ‚Ä¢ Multi-paragraph descriptions (1-20 –ø–∞—Ä–∞–≥—Ä–∞—Ñ–æ–≤)               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ STAGE 3: Multi-NLP Entity Extraction (—É–ª—É—á—à–µ–Ω–æ Perplexity!)    ‚îÇ
‚îÇ  ‚Ä¢ SpaCy (weight 1.0)                                           ‚îÇ
‚îÇ  ‚Ä¢ Natasha (weight 1.2)                                         ‚îÇ
‚îÇ  ‚Ä¢ Stanza (weight 0.8)                                          ‚îÇ
‚îÇ  ‚Ä¢ DeepPavlov (weight 1.5) ‚Üê –ù–û–í–û–ï! F1 0.94-0.97               ‚îÇ
‚îÇ  ‚Ä¢ GLiNER –¥–ª—è –∫–∞—Å—Ç–æ–º–Ω—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π ‚Üê –ù–û–í–û–ï!                      ‚îÇ
‚îÇ  ‚Ä¢ Ensemble Voting —Å –≤–µ—Å–∞–º–∏                                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ STAGE 4: Multi-Factor Confidence Scoring (–Ω–∞—à –ø–æ–¥—Ö–æ–¥!)          ‚îÇ
‚îÇ  ‚Ä¢ 5 —Ñ–∞–∫—Ç–æ—Ä–æ–≤ –∫–∞—á–µ—Å—Ç–≤–∞                                          ‚îÇ
‚îÇ  ‚Ä¢ –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–µ –ø–æ—Ä–æ–≥–∏ –ø–æ –¥–ª–∏–Ω–µ                                   ‚îÇ
‚îÇ  ‚Ä¢ –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç –î–õ–ò–ù–ù–´–ú –æ–ø–∏—Å–∞–Ω–∏—è–º (2000-3500)                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ STAGE 5: LLM Enrichment (–ù–û–í–û–ï –æ—Ç Perplexity!) - –û–ü–¶–ò–û–ù–ê–õ–¨–ù–û   ‚îÇ
‚îÇ  ‚Ä¢ LangExtract + Gemini/GPT-4                                   ‚îÇ
‚îÇ  ‚Ä¢ –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –æ–±–æ–≥–∞—â–µ–Ω–∏–µ –æ–ø–∏—Å–∞–Ω–∏–π                       ‚îÇ
‚îÇ  ‚Ä¢ –§–æ—Ä–º–∞—Ç: visual_elements, colors, atmosphere, etc.            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    OUTPUT: Enriched Descriptions                 ‚îÇ
‚îÇ  ‚Ä¢ –î–ª–∏–Ω–Ω—ã–µ (500-3500 —Å–∏–º–≤–æ–ª–æ–≤)                                  ‚îÇ
‚îÇ  ‚Ä¢ –ö–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ (multi-factor scored)                           ‚îÇ
‚îÇ  ‚Ä¢ –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ (LLM enriched)                             ‚îÇ
‚îÇ  ‚Ä¢ –ì–æ—Ç–æ–≤—ã–µ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π                            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## –°—Ä–∞–≤–Ω–µ–Ω–∏–µ: –ù–∞—à –ø–æ–¥—Ö–æ–¥ vs –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ Perplexity

| –ö–æ–º–ø–æ–Ω–µ–Ω—Ç | –ù–∞—à–µ —Ä–µ—à–µ–Ω–∏–µ | –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è Perplexity | –†–µ—à–µ–Ω–∏–µ |
|-----------|--------------|------------------------|---------|
| **–£—Ä–æ–≤–µ–Ω—å –ø–∞—Ä—Å–∏–Ω–≥–∞** | –ü–∞—Ä–∞–≥—Ä–∞—Ñ—ã | –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è/NER | ‚úÖ **–ù–ê–® –õ–£–ß–®–ï!** |
| **Multi-paragraph** | ‚úÖ 1-20 –ø–∞—Ä–∞–≥—Ä–∞—Ñ–æ–≤ | ‚ùå –ù–µ—Ç | ‚úÖ **–ù–ê–® –£–ù–ò–ö–ê–õ–ï–ù!** |
| **Multi-NLP** | ‚úÖ 3 –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞ | ‚úÖ –ü–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–æ | ‚úÖ **–ü–†–ê–í–ò–õ–¨–ù–û** |
| **DeepPavlov** | ‚ùå –ù–µ—Ç | ‚úÖ F1 0.94-0.97 | üîÑ **–î–û–ë–ê–í–ò–¢–¨!** |
| **LLM –æ–±–æ–≥–∞—â–µ–Ω–∏–µ** | ‚ùå –ù–µ—Ç | ‚úÖ LangExtract | üîÑ **–î–û–ë–ê–í–ò–¢–¨!** |
| **Dependency Parsing** | ‚ùå –ù–µ—Ç | ‚úÖ –û–ø–∏—Å–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—Ä–∞–∑—ã | üîÑ **–î–û–ë–ê–í–ò–¢–¨!** |
| **5-—Ñ–∞–∫—Ç–æ—Ä–Ω–∞—è –æ—Ü–µ–Ω–∫–∞** | ‚úÖ –£–Ω–∏–∫–∞–ª—å–Ω–æ | ‚ùå –ù–µ—Ç | ‚úÖ **–ù–ê–® –õ–£–ß–®–ï!** |
| **–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç –¥–ª–∏–Ω–Ω—ã–º** | ‚úÖ 2000-3500 = 2.5x | ‚ùå –ù–µ—Ç | ‚úÖ **–ù–ê–® –õ–£–ß–®–ï!** |
| **GLiNER** | ‚ùå –ù–µ—Ç | ‚úÖ Zero-shot | üîÑ **–î–û–ë–ê–í–ò–¢–¨!** |
| **Coreference** | ‚ùå –ù–µ—Ç | ‚úÖ –ù—É–∂–Ω–æ | üîÑ **–î–û–ë–ê–í–ò–¢–¨!** |

**–í—ã–≤–æ–¥**: –ù–∞—à paragraph-based –ø–æ–¥—Ö–æ–¥ –£–ù–ò–ö–ê–õ–ï–ù –∏ –ü–†–ê–í–ò–õ–¨–ù–´–ô!
Perplexity –ø—Ä–µ–¥–ª–æ–∂–∏–ª –î–û–ü–û–õ–ù–ï–ù–ò–Ø, –∞ –Ω–µ –∑–∞–º–µ–Ω—É!

---

## Roadmap –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏

### Week 1 (Priority 0)
- [ ] –î–µ–Ω—å 1-2: –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å DeepPavlov –≤ Multi-NLP
- [ ] –î–µ–Ω—å 3-4: –î–æ–±–∞–≤–∏—Ç—å Dependency Parsing –≤ ParagraphSegmenter
- [ ] –î–µ–Ω—å 5-6: –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å LangExtract –¥–ª—è LLM –æ–±–æ–≥–∞—â–µ–Ω–∏—è
- [ ] –î–µ–Ω—å 7: –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ –∫–Ω–∏–≥–µ "–í–µ–¥—å–º–∞–∫"

### Week 2 (Priority 1)
- [ ] –î–µ–Ω—å 1-2: –î–æ–±–∞–≤–∏—Ç—å GLiNER –¥–ª—è zero-shot –∫–∞—Ç–µ–≥–æ—Ä–∏–π
- [ ] –î–µ–Ω—å 3-5: –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å Coreference Resolution
- [ ] –î–µ–Ω—å 6-7: –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞

### Week 3 (Fine-tuning)
- [ ] –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –≤–µ—Å–æ–≤ –¥–ª—è DeepPavlov
- [ ] –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ–º–ø—Ç–æ–≤ –¥–ª—è LangExtract
- [ ] –§–∏–Ω–∞–ª—å–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
- [ ] –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è

---

## –û–∂–∏–¥–∞–µ–º—ã–µ —É–ª—É—á—à–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞

### –¢–µ–∫—É—â–∞—è —Å–∏—Å—Ç–µ–º–∞ (–±–µ–∑ Perplexity)
```
–û–∂–∏–¥–∞–Ω–∏—è:
- 100-200 –æ–ø–∏—Å–∞–Ω–∏–π –∏–∑ –∫–Ω–∏–≥–∏
- F1 –¥–ª—è –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π: ~0.85-0.90
- –°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞: 1200-1800 —Å–∏–º–≤–æ–ª–æ–≤
- –ö–∞—á–µ—Å—Ç–≤–æ –æ–ø–∏—Å–∞–Ω–∏–π: —Ö–æ—Ä–æ—à–µ–µ
```

### –° –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–µ–π Perplexity
```
–ü—Ä–æ–≥–Ω–æ–∑:
- 80-150 –æ–ø–∏—Å–∞–Ω–∏–π (–∫–∞—á–µ—Å—Ç–≤–æ > –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ)
- F1 –¥–ª—è –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π: ~0.94-0.97 (+7-12%)
- –°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞: 1500-2200 —Å–∏–º–≤–æ–ª–æ–≤
- –ö–∞—á–µ—Å—Ç–≤–æ –æ–ø–∏—Å–∞–Ω–∏–π: –û–¢–õ–ò–ß–ù–û–ï (LLM enriched)
- –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ—Å—Ç—å: –í–´–°–û–ö–ê–Ø (JSON format)
```

---

## –í—ã–≤–æ–¥—ã

1. **–ù–∞—à paragraph-based –ø–æ–¥—Ö–æ–¥ –ü–û–î–¢–í–ï–†–ñ–î–ï–ù –∫–∞–∫ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π** - Perplexity –Ω–µ –ø—Ä–µ–¥–ª–æ–∂–∏–ª –Ω–∏—á–µ–≥–æ –ø–æ–¥–æ–±–Ω–æ–≥–æ!

2. **Perplexity –ø—Ä–µ–¥–ª–æ–∂–∏–ª –î–û–ü–û–õ–ù–ï–ù–ò–Ø, –∞ –Ω–µ –∑–∞–º–µ–Ω—É**:
   - DeepPavlov –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è NER
   - LangExtract –¥–ª—è LLM –æ–±–æ–≥–∞—â–µ–Ω–∏—è
   - Dependency Parsing –¥–ª—è —Å–∏–Ω—Ç–∞–∫—Å–∏—Å–∞
   - GLiNER –¥–ª—è –≥–∏–±–∫–æ—Å—Ç–∏

3. **–ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ–¥—Ö–æ–¥ = –Ω–∞–∏–ª—É—á—à–µ–µ —Ä–µ—à–µ–Ω–∏–µ**:
   ```
   –ù–∞—à —É–Ω–∏–∫–∞–ª—å–Ω—ã–π paragraph-based parser
   + Multi-NLP —Å DeepPavlov (F1 0.94-0.97)
   + LLM enrichment —á–µ—Ä–µ–∑ LangExtract
   + Dependency Parsing –¥–ª—è –æ–ø–∏—Å–∞—Ç–µ–ª—å–Ω—ã—Ö —Ñ—Ä–∞–∑
   = –†–ï–í–û–õ–Æ–¶–ò–û–ù–ù–ê–Ø –°–ò–°–¢–ï–ú–ê –ë–ï–ó –ê–ù–ê–õ–û–ì–û–í!
   ```

4. **–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏**: DeepPavlov ‚Üí Dependency Parsing ‚Üí LangExtract

---

**–°–ª–µ–¥—É—é—â–∏–π —à–∞–≥**: –ù–∞—á–∞—Ç—å —Å –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ DeepPavlov –≤ Multi-NLP —Å–∏—Å—Ç–µ–º—É (Priority 0, Task 1)
