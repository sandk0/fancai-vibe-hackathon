# Sessions 6-7 Infrastructure Checklist

**–î–µ—Ç–∞–ª—å–Ω—ã–π —á–µ–∫–ª–∏—Å—Ç –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã—Ö —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π**

---

## üìã Pre-Deployment Infrastructure Audit

### –†–µ—Å—É—Ä—Å—ã (Memory & Disk)

#### Memory Requirements
```
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë Component               ‚îÇ Min    ‚îÇ Recommended ‚îÇ Peak Usage     ‚ïë
‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£
‚ïë PostgreSQL              ‚îÇ 512MB  ‚îÇ 1GB        ‚îÇ 512MB          ‚ïë
‚ïë Redis                   ‚îÇ 256MB  ‚îÇ 512MB      ‚îÇ 256MB          ‚ïë
‚ïë Backend (base)          ‚îÇ 512MB  ‚îÇ 1GB        ‚îÇ 1GB            ‚ïë
‚ïë - SpaCy model           ‚îÇ 400MB  ‚îÇ 400MB      ‚îÇ 400MB          ‚ïë
‚ïë - Natasha               ‚îÇ 50MB   ‚îÇ 50MB       ‚îÇ 50MB           ‚ïë
‚ïë - GLiNER model          ‚îÇ 700MB  ‚îÇ 700MB      ‚îÇ 700MB          ‚ïë
‚ïë - Stanza model (NEW)    ‚îÇ 630MB  ‚îÇ 630MB      ‚îÇ 780MB*         ‚ïë
‚ïë Celery Worker           ‚îÇ 512MB  ‚îÇ 1.5GB      ‚îÇ 1.5GB          ‚ïë
‚ïë Celery Beat             ‚îÇ 256MB  ‚îÇ 512MB      ‚îÇ 256MB          ‚ïë
‚ïë Frontend (Vite)         ‚îÇ 256MB  ‚îÇ 512MB      ‚îÇ 256MB          ‚ïë
‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£
‚ïë TOTAL (Sessions 1-5)    ‚îÇ 3.5GB  ‚îÇ 6.7GB      ‚îÇ 5.5GB          ‚ïë
‚ïë + Stanza (Session 6)    ‚îÇ +630MB ‚îÇ +630MB     ‚îÇ +780MB*        ‚ïë
‚ïë TOTAL (Sessions 6-7)    ‚îÇ 4.1GB  ‚îÇ 7.3GB      ‚îÇ 6.3GB          ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù

* Stanza runtime memory –º–æ–∂–µ—Ç –±—ã—Ç—å –≤—ã—à–µ —á–µ–º —Ä–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏
```

#### Disk Space Requirements
```
Component                   ‚îÇ Size (MB) ‚îÇ Location
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
PostgreSQL data             ‚îÇ 100-500   ‚îÇ postgres_data volume
Redis data                  ‚îÇ 50-100    ‚îÇ redis_data volume
Backend code                ‚îÇ 100-200   ‚îÇ Mounted /app
- SpaCy model               ‚îÇ 400       ‚îÇ NLP persistent volume
- Natasha                   ‚îÇ 50        ‚îÇ NLP persistent volume
- GLiNER model              ‚îÇ 700       ‚îÇ NLP persistent volume
- Stanza model (NEW)        ‚îÇ 630       ‚îÇ nlp_stanza_models volume
Frontend code               ‚îÇ 100-200   ‚îÇ Mounted /app
- node_modules              ‚îÇ 200-300   ‚îÇ frontend_node_modules
Celery worker storage       ‚îÇ 50-100    ‚îÇ Mounted /app
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
TOTAL Minimum               ‚îÇ 2.8 GB    ‚îÇ
RECOMMENDED FREE SPACE      ‚îÇ 5 GB      ‚îÇ For safety margin
```

### –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤

```bash
# –¢–µ–∫—É—â–µ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏
free -h

# –°–≤–æ–±–æ–¥–Ω–æ–µ –º–µ—Å—Ç–æ –Ω–∞ –¥–∏—Å–∫–µ
df -h

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ Docker volumes
docker system df

# –û–∂–∏–¥–∞–µ–º—ã–π –≤—ã–≤–æ–¥:
# Memory: ~3-4GB available (minimum for dev)
# Disk: ~5GB available
# Docker volumes: clean state
```

### ‚úÖ Pre-Deployment Checklist

#### Hardware & Resources
- [ ] –ú–∏–Ω–∏–º—É–º 4GB RAM –¥–æ—Å—Ç—É–ø–Ω–æ (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è 8GB+)
- [ ] –ú–∏–Ω–∏–º—É–º 5GB —Å–≤–æ–±–æ–¥–Ω–æ–≥–æ –¥–∏—Å–∫–æ–≤–æ–≥–æ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞
- [ ] CPU: 2+ cores (–¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏)
- [ ] –ò–Ω—Ç–µ—Ä–Ω–µ—Ç connection: >5 Mbps (–¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–µ–π)

#### Docker Setup
- [ ] Docker Desktop –∏–ª–∏ Docker Engine —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω
- [ ] Docker Compose v2+ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω (`docker-compose --version`)
- [ ] Docker daemon —Ä–∞–±–æ—Ç–∞–µ—Ç (`docker ps`)
- [ ] –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ä–µ—Å—É—Ä—Å–æ–≤ –≤ Docker (Settings ‚Üí Resources):
  ```
  - CPUs: 4+ (–∏–ª–∏ —á—Ç–æ –¥–æ—Å—Ç—É–ø–Ω–æ)
  - Memory: 6GB+ (–∏–ª–∏ —á—Ç–æ –¥–æ—Å—Ç—É–ø–Ω–æ)
  - Swap: 2GB+
  - Disk Image Size: 50GB+
  ```

#### Environment Configuration
- [ ] `.env` —Ñ–∞–π–ª —Å—É—â–µ—Å—Ç–≤—É–µ—Ç —Å –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–º–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–º–∏:
  ```bash
  DB_PASSWORD=<secure-password>
  REDIS_PASSWORD=<secure-password>
  SECRET_KEY=<secure-key>
  ```
- [ ] –í—Å–µ –ø—É—Ç–∏ –≤ docker-compose.yml –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã
- [ ] –ù–µ—Ç –∫–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤ –ø–æ—Ä—Ç–æ–≤:
  - 8000 (backend)
  - 5173 (frontend)
  - 5432 (postgres)
  - 6379 (redis)

#### Network Configuration
- [ ] Booked network –¥–æ—Å—Ç—É–ø–Ω–∞: `docker network inspect bookreader_network`
- [ ] DNS resolve —Ä–∞–±–æ—Ç–∞–µ—Ç –≤–Ω—É—Ç—Ä–∏ —Å–µ—Ç–∏
- [ ] –ú–µ–∂–∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–Ω–æ–µ –æ–±—â–µ–Ω–∏–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–æ

#### Volumes Configuration
- [ ] Persistent volumes –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã:
  ```bash
  docker volume ls | grep bookreader

  # –û–∂–∏–¥–∞–µ–º—ã–µ volumes:
  # bookreader_nlp_nltk_data
  # bookreader_nlp_stanza_models (NEW for Session 6)
  # bookreader_postgres_data
  # bookreader_redis_data
  # bookreader_uploaded_books
  # bookreader_frontend_node_modules
  ```

---

## üîß Configuration Files Checklist

### docker-compose.yml
- [ ] Backend service –∏–º–µ–µ—Ç volume –¥–ª—è Stanza:
  ```yaml
  volumes:
    - nlp_stanza_models:/root/stanza_resources
  ```
- [ ] Backend service –∏–º–µ–µ—Ç environment –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é:
  ```yaml
  environment:
    - STANZA_RESOURCES_DIR=/root/stanza_resources
  ```
- [ ] Memory limits —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã:
  ```yaml
  backend:
    deploy:
      resources:
        limits:
          memory: 2G
  celery-worker:
    deploy:
      resources:
        limits:
          memory: 1.5G
  ```

### Dockerfile (backend)
- [ ] BASE IMAGE: `python:3.11-slim`
- [ ] –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã (`requirements.txt`)
- [ ] NLP –º–æ–¥–µ–ª–∏ –º–æ–≥—É—Ç –∑–∞–≥—Ä—É–∂–∞—Ç—å—Å—è –≤ runtime (–Ω–µ –≤ build time)
- [ ] Health check –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É–µ—Ç:
  ```dockerfile
  HEALTHCHECK --interval=30s --timeout=10s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1
  ```

### settings_manager.py
- [ ] Stanza configuration –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É–µ—Ç (Session 6):
  ```python
  "nlp_stanza": {
      "enabled": True,
      "weight": 0.8,
      "threshold": 0.3,
      "model": "ru",
  }
  ```
- [ ] Advanced Parser configuration –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É–µ—Ç (Session 7):
  ```python
  "advanced_parser": {
      "enabled": False,  # Disabled by default
      "min_text_length": 500,
  }
  ```

### config_loader.py
- [ ] Stanza processor loading logic –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É–µ—Ç
- [ ] Advanced Parser adapter import —Ä–∞–±–æ—Ç–∞–µ—Ç
- [ ] Graceful degradation –ø—Ä–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π

---

## üöÄ Deployment Steps with Infrastructure Verification

### Step 1: Verify Base Infrastructure

```bash
# Project location
cd /Users/sandk/Documents/GitHub/fancai-vibe-hackathon

# Check docker setup
docker --version                          # Docker version
docker-compose --version                 # v2+
docker ps                                 # Daemon working

# Check available resources
free -h                                   # Memory
df -h                                     # Disk space
docker system df                          # Docker disk usage
```

**‚úÖ Expected Output:**
```
Docker version 24.0+
Docker Compose version 2.20+
CONTAINERS: 0
MEMORY: 3GB+ available
DISK: 5GB+ available
```

### Step 2: Prepare Docker Compose Environment

```bash
# Create/update .env if not exists
touch .env

# Add required variables (if not already there)
if ! grep -q "DB_PASSWORD" .env; then
  echo "DB_PASSWORD=$(openssl rand -base64 32)" >> .env
fi

if ! grep -q "REDIS_PASSWORD" .env; then
  echo "REDIS_PASSWORD=$(openssl rand -base64 32)" >> .env
fi

if ! grep -q "SECRET_KEY" .env; then
  echo "SECRET_KEY=$(openssl rand -base64 64)" >> .env
fi

# Verify
cat .env
```

### Step 3: Start Base Services

```bash
# Start only PostgreSQL and Redis (no NLP models yet)
docker-compose up -d postgres redis

# Wait for health checks
sleep 10

# Verify they're healthy
docker-compose ps postgres redis
# Both should show: healthy in STATUS
```

### Step 4: Download Stanza Model (Session 6)

```bash
# Start backend service (will inherit from postgres/redis health)
docker-compose up -d backend

# Wait for backend to be ready
sleep 30

# Download Stanza model (this takes 10-20 minutes)
echo "Starting Stanza model download..."
docker-compose exec backend python -c "
import sys
import stanza
try:
    print('Downloading Stanza Russian model...')
    stanza.download('ru', verbose=True)
    print('‚úÖ Stanza model downloaded successfully')
    sys.exit(0)
except Exception as e:
    print(f'‚ùå Error: {e}')
    sys.exit(1)
"

# Monitor download progress
docker-compose logs -f backend | grep -i stanza
```

**‚è±Ô∏è Expected Time:** 10-20 minutes (depends on internet speed)

**‚úÖ Verify:**
```bash
# Check model files
docker-compose exec backend ls -lh /root/stanza_resources/ru/

# Expected output:
# total ~630MB
# -rw-r--r-- tokenize/default.pt (~100MB)
# -rw-r--r-- pos/default.pt (~70MB)
# -rw-r--r-- lemma/default.pt (~20MB)
# -rw-r--r-- depparse/default.pt (~300MB) <- Main component
# -rw-r--r-- ner/default.pt (~50MB)
```

### Step 5: Start Remaining Services

```bash
# Start celery worker, celery beat, and frontend
docker-compose up -d celery-worker celery-beat frontend

# Wait for all services
sleep 30

# Verify all are running
docker-compose ps

# Expected: All services in "Up" state
```

### Step 6: Verify Infrastructure Health

```bash
# Check all services are healthy
docker-compose ps | grep -E "backend|postgres|redis"
# All should show: healthy or Up

# Check resource usage
docker stats --no-stream
# Backend should use: ~1-2GB memory, <30% CPU

# Check logs for errors
docker-compose logs backend | grep -i error
# Should be empty or only INFO level

# Check network connectivity
docker-compose exec backend curl -f http://localhost:8000/health
# Expected: {"status": "healthy"}
```

### Step 7: Verify Feature Flags & Configuration

```bash
# Check Stanza is enabled in settings
docker-compose exec backend python -c "
from app.services.settings_manager import settings_manager
import json
stanza_config = settings_manager._settings.get('nlp_stanza', {})
print('Stanza Config:')
print(json.dumps(stanza_config, indent=2))
print(f\"Enabled: {stanza_config.get('enabled')}\")
"

# Check Advanced Parser configuration
docker-compose exec backend python -c "
from app.services.settings_manager import settings_manager
import json
ap_config = settings_manager._settings.get('advanced_parser', {})
print('Advanced Parser Config:')
print(json.dumps(ap_config, indent=2))
print(f\"Enabled: {ap_config.get('enabled')}\")
"

# Both should show correctly loaded configurations
```

---

## üîÑ Monitoring & Health Checks

### Continuous Monitoring During Deployment

```bash
# Terminal 1: Watch Docker stats
watch -n 1 'docker stats --no-stream | grep -E "CONTAINER|backend|worker"'

# Terminal 2: Follow backend logs
docker-compose logs -f backend

# Terminal 3: Monitor memory usage of Stanza loading
docker exec bookreader-backend ps aux | grep stanza
```

### Health Check Endpoints

```bash
# General health
curl -s http://localhost:8000/health | jq .

# Detailed NLP status (if endpoint exists)
curl -s http://localhost:8000/api/v1/admin/multi-nlp-settings/status | jq .

# Frontend status
curl -s http://localhost:5173 -I | head -3
```

---

## üö® Infrastructure Troubleshooting

### Issue: Out of Memory

**Symptoms:**
```
docker-compose logs backend | grep -i "oomkilled\|memory\|killed"
```

**Solutions:**
```bash
# 1. Increase Docker memory limit
# Docker Desktop ‚Üí Settings ‚Üí Resources ‚Üí Memory slider

# 2. Increase docker-compose limits
# Edit docker-compose.yml:
deploy:
  resources:
    limits:
      memory: 3G  # Increase from 2G

# 3. Restart with new limits
docker-compose down
docker-compose up -d

# 4. Monitor
docker stats backend
```

### Issue: Disk Space Exhausted

**Symptoms:**
```
docker-compose logs backend | grep -i "no space\|disk"
```

**Solutions:**
```bash
# Check what's using space
du -sh /var/lib/docker/*

# Clean up unused images/volumes
docker system prune -a  # WARNING: removes all unused
docker volume prune     # Safer: only volumes

# Increase Docker Desktop disk image size
# Settings ‚Üí Resources ‚Üí Disk Image Size slider
```

### Issue: Port Conflicts

**Symptoms:**
```
docker-compose logs backend | grep "Address already in use"
```

**Solutions:**
```bash
# Find what's using the port
lsof -i :8000

# Kill the process or change port in docker-compose.yml
ports:
  - "8001:8000"  # Change external port

# Restart
docker-compose restart backend
```

### Issue: Network Connectivity Issues

**Symptoms:**
```
docker-compose logs backend | grep "cannot connect\|connection refused"
```

**Solutions:**
```bash
# Check network
docker network inspect bookreader_network

# Verify DNS resolution
docker-compose exec backend ping postgres
docker-compose exec backend ping redis

# Restart network
docker-compose down
docker network prune
docker-compose up -d
```

---

## üìä Post-Deployment Infrastructure Validation

After all services are running:

```bash
# 1. Resource usage validation
docker stats --no-stream

# Expected:
# backend:    ~1.5-2GB memory, <30% CPU
# postgres:   ~200-300MB memory, <10% CPU
# redis:      ~100-150MB memory, <5% CPU
# worker:     ~800MB memory, <20% CPU
# frontend:   ~100-150MB memory, <5% CPU

# 2. Volume usage
docker system df

# Expected:
# IMAGES: 4-5 images, ~2-3GB
# CONTAINERS: 5 containers, ~500MB
# VOLUMES: 6-7 volumes, ~2GB

# 3. Network verification
docker-compose exec backend ping -c 1 postgres
docker-compose exec backend ping -c 1 redis
docker-compose exec backend curl -s http://frontend:5173 -I

# All should succeed

# 4. Database connectivity
docker-compose exec backend python -c "
import asyncio
from app.core.database import get_db
async def test():
    async with get_db() as session:
        result = await session.execute('SELECT 1')
        print('‚úÖ Database connected')
asyncio.run(test())
"

# 5. NLP models loaded
docker-compose exec backend python -c "
import spacy
import stanza
import natasha
print('‚úÖ SpaCy loaded')
stanza.Pipeline('ru')
print('‚úÖ Stanza loaded')
natasha.Segmenter()
print('‚úÖ Natasha loaded')
"
```

---

## üéØ Infrastructure Verification Checklist

### Final Validation

- [ ] All Docker services running (`docker-compose ps`)
- [ ] All services healthy (STATUS: healthy or Up)
- [ ] Memory usage stable and within limits
- [ ] Disk space available (>2GB free)
- [ ] Network connectivity working (services can reach each other)
- [ ] Stanza model files present (~630MB)
- [ ] API endpoints responding (health, admin endpoints)
- [ ] No ERROR logs in services
- [ ] Database migrations complete (no pending)
- [ ] Redis cache accessible
- [ ] Celery workers ready

### Performance Baseline

- [ ] Backend response time: <1 second for simple requests
- [ ] Processing time (descriptions): 1.5-3 seconds per chapter
- [ ] F1 score: >0.87 (baseline from Sessions 1-5)
- [ ] Memory growth stable (no memory leaks)
- [ ] CPU usage normal (<50% when idle)

---

**Document Created:** 2025-11-23
**Version:** 1.0
**Status:** Production-Ready
**Audience:** DevOps Engineers, System Administrators
