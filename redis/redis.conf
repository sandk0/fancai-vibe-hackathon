# ============================================================================
# Redis Configuration for BookReader AI - Production/Staging
# ============================================================================
# Target Environment: 4GB RAM server, 2 CPU cores
# Optimization Target: Caching layer для development/staging (10-50 concurrent users)
#
# Memory Budget: 256-512MB
# Use Cases:
#   - Session storage (JWT tokens, reading progress)
#   - Celery task queue/results
#   - API response caching
#   - Rate limiting
#
# Last Updated: 2025-11-15
# Performance Strategy: Balanced (persistence + performance)
# ============================================================================

# ============================================================================
# NETWORK
# ============================================================================

# Accept connections from any IP (Docker internal network)
bind 0.0.0.0

# Listen on default port
port 6379

# Close connection after client idle for N seconds
# 300 = 5 minutes (prevents resource exhaustion)
timeout 300

# TCP keepalive (send ACKs to detect dead connections)
# 300 seconds = 5 minutes
tcp-keepalive 300

# Maximum number of client connections
# Conservative для staging environment
maxclients 1000

# TCP backlog (queue size for pending connections)
# 511 = default, sufficient для staging
tcp-backlog 511

# ============================================================================
# MEMORY CONFIGURATION
# ============================================================================

# Maximum memory limit (CRITICAL для preventing OOM)
# 512MB для staging environment
maxmemory 512mb

# Eviction policy when maxmemory reached
# allkeys-lru = remove least recently used keys (good для caching)
# Options:
#   - allkeys-lru: remove any key, least recently used
#   - volatile-lru: remove expiring keys only, least recently used
#   - allkeys-lfu: remove any key, least frequently used
#   - volatile-lfu: remove expiring keys only, least frequently used
#   - allkeys-random: remove any key, random
#   - volatile-random: remove expiring keys only, random
#   - volatile-ttl: remove expiring keys, shortest TTL first
#   - noeviction: return errors when memory limit reached
maxmemory-policy allkeys-lru

# Samples для LRU/LFU algorithm (higher = more accurate, but slower)
# 5 = good balance между accuracy и performance
maxmemory-samples 5

# ============================================================================
# PERSISTENCE - RDB (Snapshots)
# ============================================================================
# RDB creates point-in-time snapshots at specified intervals

# Save snapshot if:
#   - At least 1 key changed in 15 minutes
#   - At least 10 keys changed in 5 minutes
#   - At least 10,000 keys changed in 1 minute
save 900 1
save 300 10
save 60 10000

# Alternative: disable snapshots entirely (uncomment for pure cache)
# save ""

# RDB file location and name
dbfilename dump.rdb
dir /data

# Compress RDB files with LZF compression
rdbcompression yes

# Checksum RDB files (detect corruption)
rdbchecksum yes

# Stop accepting writes if RDB snapshot fails
# yes = safer (data integrity), но может вызвать downtime
# no = continue despite snapshot failures (для staging)
stop-writes-on-bgsave-error yes

# ============================================================================
# PERSISTENCE - AOF (Append-Only File)
# ============================================================================
# AOF logs every write operation (more durable than RDB)

# Enable AOF (более надежно для production)
# yes = enable AOF persistence
appendonly yes

# AOF filename
appendfilename "appendonly.aof"

# AOF fsync policy (how often to write to disk)
# Options:
#   - always: fsync every write (slowest, safest)
#   - everysec: fsync every second (balanced) ✓ RECOMMENDED
#   - no: let OS decide (fastest, least safe)
appendfsync everysec

# Don't fsync while rewriting AOF (better performance)
no-appendfsync-on-rewrite yes

# Automatic AOF rewrite (compact file)
# Trigger rewrite when AOF grows by 100% and is at least 64MB
auto-aof-rewrite-percentage 100
auto-aof-rewrite-min-size 64mb

# Load truncated AOF file (recover from incomplete writes)
aof-load-truncated yes

# Use RDB-AOF hybrid format for faster loading
aof-use-rdb-preamble yes

# ============================================================================
# SECURITY
# ============================================================================

# Require password for all commands
# Password set via environment variable in docker-compose
# DO NOT hardcode password here in production!
# requirepass ${REDIS_PASSWORD}

# Rename dangerous commands (prevents accidental data loss)
# FLUSHDB and FLUSHALL can destroy all data
rename-command FLUSHDB ""
rename-command FLUSHALL ""

# CONFIG command can modify runtime configuration
# Rename to secret name для security
rename-command CONFIG "CONFIG_4dM1n_0nLy_S3cR3t"

# Disable other dangerous commands
# rename-command SHUTDOWN ""
# rename-command DEBUG ""

# Protected mode (reject connections from non-localhost without password)
# Disabled in Docker as we use internal network + password
protected-mode no

# ============================================================================
# PERFORMANCE
# ============================================================================

# Slow log (log queries slower than N microseconds)
# 10000 microseconds = 10ms
slowlog-log-slower-than 10000

# Slow log max length (number of entries to keep)
slowlog-max-len 128

# Latency monitoring threshold (milliseconds)
# Log events causing latency > 100ms
latency-monitor-threshold 100

# Database count (number of logical databases)
# Default 16, но обычно используется только 0-2
databases 16

# Disable Redis cluster mode (not needed for staging)
# cluster-enabled no

# ============================================================================
# MEMORY OPTIMIZATION
# ============================================================================
# Optimize data structures для memory efficiency

# Hash (используется для objects/dicts)
# Use ziplist (compact representation) if:
#   - Hash has ≤512 entries AND
#   - Each entry value ≤64 bytes
hash-max-ziplist-entries 512
hash-max-ziplist-value 64

# List (используется для queues)
# Use ziplist for small lists
# -2 = max size 8KB
list-max-ziplist-size -2

# Don't compress list nodes (0 = no compression)
# Compression saves memory but adds CPU overhead
list-compress-depth 0

# Set (используется для unique collections)
# Use intset (compact) for sets of integers
# if all values are integers and set has ≤512 elements
set-max-intset-entries 512

# Sorted Set (используется для rankings, time series)
# Use ziplist if:
#   - Sorted set has ≤128 entries AND
#   - Each entry ≤64 bytes
zset-max-ziplist-entries 128
zset-max-ziplist-value 64

# HyperLogLog (cardinality estimation)
# Sparse representation limit (bytes)
hll-sparse-max-bytes 3000

# Stream (используется для event logs)
# Use listpack (compact) representation
stream-node-max-bytes 4096
stream-node-max-entries 100

# ============================================================================
# ACTIVE DEFRAGMENTATION
# ============================================================================
# Reduce memory fragmentation by reorganizing memory

# Enable active defragmentation
# Defragments memory in background для long-running instances
activedefrag yes

# Minimum amount of fragmentation to start defrag
# 10% = start when waste ≥10% of allocated memory
active-defrag-threshold-lower 10

# Maximum fragmentation to trigger aggressive defrag
# 100% = very aggressive at 100% fragmentation
active-defrag-threshold-upper 100

# Minimum size of fragmented memory to trigger defrag
# Don't defrag if fragmented memory <100MB
active-defrag-ignore-bytes 100mb

# CPU percentage для defragmentation
# 5-75% range = balance между performance impact и defrag speed
active-defrag-cycle-min 5
active-defrag-cycle-max 75

# ============================================================================
# REPLICATION (for future production setup)
# ============================================================================
# Standby replica settings (not used in staging)

# Make this instance a replica of another Redis server
# replicaof <masterip> <masterport>

# Authenticate with master server
# masterauth <master-password>

# Replica read-only mode (recommended)
replica-read-only yes

# Replication timeout
repl-timeout 60

# Disable TCP_NODELAY on replica socket
# no = enable TCP_NODELAY (lower latency, recommended)
repl-disable-tcp-nodelay no

# Replica priority (for failover)
# Lower number = higher priority (0 = never promote)
replica-priority 100

# ============================================================================
# ADVANCED CONFIGURATION
# ============================================================================

# Lua scripting time limit (milliseconds)
# 5000ms = 5 seconds max для Lua scripts
lua-time-limit 5000

# Enable keyspace notifications (для pub/sub patterns)
# Options:
#   K = keyspace events (published to __keyspace@<db>__ channels)
#   E = keyevent events (published to __keyevent@<db>__ channels)
#   g = generic commands (DEL, EXPIRE, RENAME, etc.)
#   $ = string commands
#   l = list commands
#   s = set commands
#   h = hash commands
#   z = sorted set commands
#   x = expired events
#   e = evicted events
#   A = alias для "g$lshzxe" (all events)
# Example: "Ex" = keyevent для expired events
# notify-keyspace-events ""

# Client output buffer limits
# Format: <class> <hard-limit> <soft-limit> <soft-seconds>
# If client output buffer exceeds limits, disconnect client

# Normal clients (regular connections)
client-output-buffer-limit normal 0 0 0

# Replica clients (replication connections)
client-output-buffer-limit replica 256mb 64mb 60

# Pub/sub clients
client-output-buffer-limit pubsub 32mb 8mb 60

# Frequency of server cron tasks (Hz)
# Higher = more responsive, но больше CPU usage
# 10 = default, good balance
hz 10

# Dynamic Hz (adjust based on load)
# Increase Hz when many clients connected
dynamic-hz yes

# Enable AOF rewrite incremental fsync
# Prevents I/O spikes during AOF rewrite
aof-rewrite-incremental-fsync yes

# Enable RDB save incremental fsync
# Prevents I/O spikes during RDB save
rdb-save-incremental-fsync yes

# ============================================================================
# LOGGING
# ============================================================================

# Log level
# Options: debug, verbose, notice, warning
# notice = production default
loglevel notice

# Log file location
# "" = log to stdout (Docker captures this)
logfile ""

# Enable syslog
# syslog-enabled no

# Syslog identity
# syslog-ident redis

# Syslog facility (LOCAL0-LOCAL7)
# syslog-facility local0

# ============================================================================
# NOTES
# ============================================================================
#
# Memory usage calculation (для 512MB maxmemory):
# - Data storage: ~400MB (после compression)
# - Overhead: ~100MB (data structures, fragmentation)
# - Reserved: ~12MB (replication buffers, slow log, etc.)
#
# Total Redis memory: ~512MB (peak)
#
# With 4GB server RAM:
# - PostgreSQL: ~1.7GB (peak)
# - Redis: ~512MB
# - Backend/Celery: ~1GB
# - OS + overhead: ~800MB
#
# Use cases for Redis in BookReader AI:
# 1. Session storage (db=0) - user sessions, JWT tokens
# 2. Celery broker (db=1) - task queue
# 3. Celery results (db=2) - task results cache
# 4. API caching (db=3) - cached API responses
# 5. Rate limiting (db=4) - request rate limits
#
# Production recommendations:
# 1. Enable Redis Sentinel для high availability
# 2. Setup replication (master-replica)
# 3. Monitor memory usage (MEMORY STATS)
# 4. Monitor slow log (SLOWLOG GET)
# 5. Configure backup strategy (RDB snapshots to S3)
# 6. Use Redis Cluster для horizontal scaling (if needed)
#
# Performance tuning для staging:
# - Optimize for cache hit ratio >90%
# - Aggressive eviction policy (allkeys-lru)
# - Balanced persistence (AOF everysec + RDB snapshots)
# - Active defragmentation для long-running instances
#
# Monitoring commands (via redis-cli):
#
# -- Memory usage
# INFO MEMORY
#
# -- Keyspace statistics
# INFO KEYSPACE
#
# -- Slow queries
# SLOWLOG GET 10
#
# -- Cache hit ratio
# INFO STATS | grep keyspace
#
# -- Current connections
# INFO CLIENTS
#
# -- Persistence status
# INFO PERSISTENCE
#
# -- Replication status
# INFO REPLICATION
#
# ============================================================================
