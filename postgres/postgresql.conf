# ============================================================================
# PostgreSQL Configuration for BookReader AI - Production/Staging
# ============================================================================
# Target Environment: 4GB RAM server, 2 CPU cores, 100GB storage
# Optimization Target: Development/Staging workload (10-50 concurrent users)
#
# Memory Budget:
#   - PostgreSQL allocation: 512MB-1GB
#   - Expected concurrent connections: 100 (conservative)
#   - Database size: ~5-10GB (books, images metadata)
#
# Last Updated: 2025-11-15
# Performance Tuning Strategy: Conservative settings для shared hosting
# ============================================================================

# ============================================================================
# MEMORY CONFIGURATION (4GB RAM server)
# ============================================================================
# Conservative settings для shared hosting environment
# Total PostgreSQL memory footprint: ~850MB (shared_buffers + connection overhead)

# Memory для кэша (25% от доступной RAM для PostgreSQL)
# Рекомендация: 25% от server RAM allocated to PostgreSQL
shared_buffers = 256MB

# Оценка доступной памяти для OS cache (50% от server RAM)
# PostgreSQL uses OS page cache for additional caching
# Higher values help query planner make better decisions
effective_cache_size = 1GB

# Память на операцию сортировки/хэша (shared_buffers / max_connections)
# Each connection can use this amount for sorting/hashing
# 256MB / 100 connections = ~2.5MB, но 4MB для безопасности
work_mem = 4MB

# Память для VACUUM, CREATE INDEX, ALTER TABLE ADD FOREIGN KEY
# Can be set higher as these operations run less frequently
maintenance_work_mem = 64MB

# WAL buffers (1/32 от shared_buffers, max 16MB)
# -1 = auto (1/32 of shared_buffers)
# Manual setting для predictability
wal_buffers = 8MB

# Kernel shared memory (should match shared_buffers)
# try = use huge pages if available (performance boost on Linux)
huge_pages = try

# ============================================================================
# CONNECTION CONFIGURATION
# ============================================================================
# Уменьшено с 200 до 100 для экономии памяти
# Each connection consumes ~10MB RAM
# 100 connections * 10MB = ~1GB RAM для connections
max_connections = 100

# Reserve connections для superuser (maintenance, emergency access)
superuser_reserved_connections = 3

# Connection timeout (close idle connections)
# 0 = disabled (не рекомендуется для production)
# Set to 5 minutes для staging environment
# Uncomment in production:
# idle_in_transaction_session_timeout = 300000  # 5 minutes

# ============================================================================
# QUERY PLANNING
# ============================================================================
# Query optimizer parameters

# Cost of random page fetch (default 4.0 for HDD)
# For SSD: 1.0-1.5 (faster random access)
random_page_cost = 1.1

# Number of concurrent disk I/O operations
# For SSD: 200+ (high parallelism)
# For HDD: 2-4
effective_io_concurrency = 200

# Statistics target (1-10000, default 100)
# Higher = better query plans, but slower ANALYZE
# 100 is good balance for most workloads
default_statistics_target = 100

# Enable/disable various plan types
# Keep all enabled for flexibility
enable_partitionwise_join = on
enable_partitionwise_aggregate = on

# ============================================================================
# WRITE AHEAD LOG (WAL)
# ============================================================================
# WAL configuration для reliability и replication support

# WAL level: minimal, replica, logical
# replica = support для streaming replication (рекомендуется)
wal_level = replica

# Maximum size of WAL (автоматические checkpoints)
# Large value = less frequent checkpoints = better write performance
# Small value = faster crash recovery
max_wal_size = 1GB

# Minimum size of WAL to keep
min_wal_size = 256MB

# WAL compression (reduce disk I/O)
# on = compress WAL records (CPU overhead, но меньше I/O)
wal_compression = on

# Checkpoint completion target (0.0-1.0)
# 0.9 = spread checkpoint I/O over 90% of checkpoint interval
# Higher = smoother I/O, lower spike impact
checkpoint_completion_target = 0.9

# Checkpoint timeout (time-based checkpoints)
# Default: 5min, для staging можно увеличить до 10min
checkpoint_timeout = 10min

# Archive mode (for point-in-time recovery)
# Disabled for staging, enable for production backups
# archive_mode = off
# archive_command = 'test ! -f /mnt/server/archivedir/%f && cp %p /mnt/server/archivedir/%f'

# ============================================================================
# REPLICATION (for future production setup)
# ============================================================================
# Standby server settings (not used in staging)

# Max number of replication connections
# Disabled for staging to save resources
max_wal_senders = 0

# WAL segments to keep for replication
# wal_keep_size = 1GB

# Replication timeout
# wal_sender_timeout = 60s

# ============================================================================
# AUTOVACUUM (Critical for performance)
# ============================================================================
# Automatic VACUUM and ANALYZE to prevent table bloat and update statistics

# Enable autovacuum (CRITICAL - always on!)
autovacuum = on

# Number of autovacuum worker processes
# 2 workers для 2 CPU cores
autovacuum_max_workers = 2

# Time between autovacuum runs (default 1min)
autovacuum_naptime = 1min

# Minimum number of tuple updates/deletes before vacuum
# Lower = more aggressive vacuuming
autovacuum_vacuum_threshold = 50

# Minimum number of tuple updates/inserts before analyze
autovacuum_analyze_threshold = 50

# Fraction of table size to add to threshold
# 0.1 = vacuum when 10% of table changed
autovacuum_vacuum_scale_factor = 0.1

# Fraction of table size to add to analyze threshold
# 0.05 = analyze when 5% of table changed (more aggressive)
autovacuum_analyze_scale_factor = 0.05

# Cost-based vacuum delay (to avoid I/O spikes)
# -1 = use vacuum_cost_delay
autovacuum_vacuum_cost_delay = -1

# Autovacuum cost limit (higher = more aggressive)
# -1 = use vacuum_cost_limit
autovacuum_vacuum_cost_limit = -1

# ============================================================================
# LOGGING (для debugging и monitoring)
# ============================================================================
# Log configuration для production troubleshooting

# Where to log
logging_collector = on
log_directory = '/var/log/postgresql'
log_filename = 'postgresql-%Y-%m-%d.log'

# Log rotation
log_rotation_age = 1d
log_rotation_size = 100MB
log_truncate_on_rotation = on

# When to log
# Log all queries taking longer than 1 second
log_min_duration_statement = 1000

# Log line prefix (timestamp, PID, user, database, etc.)
log_line_prefix = '%t [%p]: [%l-1] user=%u,db=%d,app=%a,client=%h '

# Log checkpoints (для monitoring I/O patterns)
log_checkpoints = on

# Log connections/disconnections (для security monitoring)
log_connections = on
log_disconnections = on

# Log lock waits (для diagnosing deadlocks)
log_lock_waits = on

# Log temporary files (для finding queries needing optimization)
# 0 = log all temp files
log_temp_files = 0

# Log autovacuum actions (для monitoring table health)
log_autovacuum_min_duration = 0

# Error reporting level
# WARNING = log warnings and errors
log_min_messages = warning
log_min_error_statement = error

# ============================================================================
# STATISTICS COLLECTION
# ============================================================================
# Query and table statistics для monitoring

# Collect query execution statistics
track_activities = on
track_counts = on
track_io_timing = on
track_functions = all

# Statement statistics (requires pg_stat_statements extension)
# Configured in shared_preload_libraries below
# pg_stat_statements.max = 10000
# pg_stat_statements.track = all

# ============================================================================
# CLIENT CONNECTION DEFAULTS
# ============================================================================
# Default settings для client connections

# Timezone (use UTC for consistency)
timezone = 'UTC'

# Date/time style (ISO format recommended)
datestyle = 'iso, mdy'

# Locale для text operations
lc_messages = 'en_US.UTF-8'
lc_monetary = 'en_US.UTF-8'
lc_numeric = 'en_US.UTF-8'
lc_time = 'en_US.UTF-8'

# Default text search configuration
# russian = поддержка русского языка для full-text search
default_text_search_config = 'pg_catalog.russian'

# ============================================================================
# PERFORMANCE EXTENSIONS
# ============================================================================
# Load extensions at server start

# pg_stat_statements = query performance monitoring
shared_preload_libraries = 'pg_stat_statements'

# pg_stat_statements configuration
pg_stat_statements.max = 1000
pg_stat_statements.track = all
pg_stat_statements.track_utility = on
pg_stat_statements.save = on

# ============================================================================
# LOCK MANAGEMENT
# ============================================================================
# Deadlock detection and timeouts

# Deadlock timeout (time to wait before checking for deadlock)
# 1s = balance между false positives и deadlock detection speed
deadlock_timeout = 1s

# Lock timeout (maximum time to wait for a lock)
# 0 = disabled (wait forever)
# Uncomment for production to prevent lock queues:
# lock_timeout = 30000  # 30 seconds

# Statement timeout (maximum query execution time)
# 0 = disabled
# Set in application via connection string (already configured in database.py)
# statement_timeout = 30000  # 30 seconds

# ============================================================================
# RESOURCE USAGE (SECURITY)
# ============================================================================
# Prevent resource exhaustion attacks

# Maximum memory per query (to prevent memory exhaustion)
# 0 = unlimited (not recommended for production)
# Uncomment for production:
# work_mem_limit = 512MB

# Temporary file size limit per session
# -1 = unlimited
# Set to 2GB to prevent disk exhaustion
temp_file_limit = 2GB

# Maximum locks per transaction
max_locks_per_transition = 64

# ============================================================================
# VACUUM CONFIGURATION
# ============================================================================
# Manual VACUUM settings (for scheduled maintenance)

# Vacuum cost delay (milliseconds to sleep between operations)
# 0 = no delay (full speed, но высокая I/O нагрузка)
# 10-20 = reasonable для production (balance)
vacuum_cost_delay = 10

# Vacuum cost limit (accumulated cost before sleeping)
# Higher = more aggressive vacuuming
vacuum_cost_limit = 200

# ============================================================================
# BACKGROUND WRITER
# ============================================================================
# Background writer для smoothing I/O

# Delay between background writer rounds
bgwriter_delay = 200ms

# Maximum number of buffers written per round
bgwriter_lru_maxpages = 100

# Multiplier для buffers to scan
bgwriter_lru_multiplier = 2.0

# ============================================================================
# QUERY TUNING
# ============================================================================
# Fine-tune query execution

# Join collapse limit (number of FROM items to optimize)
# Higher = better plans для complex joins, но slower planning
from_collapse_limit = 8

# Join order optimization limit
join_collapse_limit = 8

# Cursor tuple fraction (для queries с cursors)
cursor_tuple_fraction = 0.1

# ============================================================================
# NOTES
# ============================================================================
#
# Memory calculation (для 4GB RAM server):
# - shared_buffers: 256MB
# - max_connections * work_mem: 100 * 4MB = 400MB
# - maintenance_work_mem: 64MB (only during VACUUM/INDEX)
# - wal_buffers: 8MB
# - Overhead (per connection): ~10MB * 100 = 1000MB
#
# Total PostgreSQL memory: ~1.7GB (peak with all connections)
# Recommended server RAM for PostgreSQL: 2GB minimum
#
# With 4GB server RAM:
# - PostgreSQL: ~1.7GB (peak)
# - Redis: ~512MB
# - Backend/Celery: ~1GB
# - OS + overhead: ~800MB
#
# Performance tuning для staging:
# - Optimize for read-heavy workload (bookmarks, reading progress)
# - Aggressive autovacuum для preventing table bloat
# - Conservative connection pool (100 max)
# - Query timeout protection (30s)
#
# Production recommendations:
# 1. Increase shared_buffers to 512MB (если dedicated server)
# 2. Enable connection pooling (PgBouncer) для reducing connection overhead
# 3. Setup replication для high availability
# 4. Configure point-in-time recovery (archive_mode)
# 5. Monitor with pg_stat_statements и pg_stat_activity
# 6. Set lock_timeout и statement_timeout для preventing stuck queries
#
# Monitoring queries:
#
# -- Current connections
# SELECT count(*) FROM pg_stat_activity;
#
# -- Slow queries (from pg_stat_statements)
# SELECT query, calls, mean_exec_time, total_exec_time
# FROM pg_stat_statements
# ORDER BY mean_exec_time DESC
# LIMIT 10;
#
# -- Table bloat (requires VACUUM)
# SELECT schemaname, tablename,
#        pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) AS size
# FROM pg_tables
# WHERE schemaname = 'public'
# ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC;
#
# -- Lock monitoring
# SELECT * FROM pg_locks WHERE NOT granted;
#
# ============================================================================
